/data/softws_up/miniconda3/envs/vae/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0214 18:46:15.424368 140065834050496 torch/distributed/run.py:779] 
W0214 18:46:15.424368 140065834050496 torch/distributed/run.py:779] *****************************************
W0214 18:46:15.424368 140065834050496 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0214 18:46:15.424368 140065834050496 torch/distributed/run.py:779] *****************************************
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
Model senet154 created, param count: 115088984
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bilinear
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
NVIDIA APEX not installed. AMP off.
Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.
Scheduled epochs: 160
Train: 0 [   0/10009 (  0%)]  Loss:  7.028358 (7.0284)  Time: 13.277s,    9.64/s  (13.277s,    9.64/s)  LR: 1.000e-04  Data: 9.270 (9.270)
Train: 0 [   1/10009 (  0%)]  Loss:  6.987080 (7.0077)  Time: 0.351s,  364.76/s  (6.814s,   18.78/s)  LR: 1.000e-04  Data: 0.009 (4.640)
Train: 0 [   2/10009 (  0%)]  Loss:  7.001822 (7.0058)  Time: 0.266s,  480.44/s  (4.631s,   27.64/s)  LR: 1.000e-04  Data: 0.007 (3.095)
Train: 0 [   3/10009 (  0%)]  Loss:  6.944425 (6.9904)  Time: 1.722s,   74.32/s  (3.904s,   32.79/s)  LR: 1.000e-04  Data: 0.065 (2.338)
Train: 0 [   4/10009 (  0%)]  Loss:  6.954519 (6.9832)  Time: 0.873s,  146.70/s  (3.298s,   38.81/s)  LR: 1.000e-04  Data: 0.006 (1.872)
Train: 0 [   5/10009 (  0%)]  Loss:  6.950188 (6.9777)  Time: 0.265s,  482.93/s  (2.792s,   45.84/s)  LR: 1.000e-04  Data: 0.006 (1.561)
Train: 0 [   6/10009 (  0%)]  Loss:  7.011766 (6.9826)  Time: 0.270s,  474.80/s  (2.432s,   52.63/s)  LR: 1.000e-04  Data: 0.008 (1.339)
Train: 0 [   7/10009 (  0%)]  Loss:  7.030183 (6.9885)  Time: 2.621s,   48.83/s  (2.456s,   52.12/s)  LR: 1.000e-04  Data: 2.301 (1.459)
Train: 0 [   8/10009 (  0%)]  Loss:  6.963247 (6.9857)  Time: 0.312s,  410.27/s  (2.217s,   57.72/s)  LR: 1.000e-04  Data: 0.013 (1.299)
Train: 0 [   9/10009 (  0%)]  Loss:  6.998112 (6.9870)  Time: 0.262s,  487.95/s  (2.022s,   63.31/s)  LR: 1.000e-04  Data: 0.006 (1.169)
Train: 0 [  10/10009 (  0%)]  Loss:  6.889179 (6.9781)  Time: 0.264s,  485.20/s  (1.862s,   68.74/s)  LR: 1.000e-04  Data: 0.007 (1.064)
Train: 0 [  11/10009 (  0%)]  Loss:  7.017940 (6.9814)  Time: 4.111s,   31.14/s  (2.050s,   62.45/s)  LR: 1.000e-04  Data: 3.811 (1.293)
Train: 0 [  12/10009 (  0%)]  Loss:  6.989255 (6.9820)  Time: 0.599s,  213.63/s  (1.938s,   66.05/s)  LR: 1.000e-04  Data: 0.008 (1.194)
Train: 0 [  13/10009 (  0%)]  Loss:  7.047697 (6.9867)  Time: 0.275s,  465.84/s  (1.819s,   70.36/s)  LR: 1.000e-04  Data: 0.010 (1.109)
Train: 0 [  14/10009 (  0%)]  Loss:  6.981152 (6.9863)  Time: 0.271s,  472.70/s  (1.716s,   74.60/s)  LR: 1.000e-04  Data: 0.010 (1.036)
Train: 0 [  15/10009 (  0%)]  Loss:  6.971037 (6.9854)  Time: 2.815s,   45.46/s  (1.785s,   71.72/s)  LR: 1.000e-04  Data: 2.498 (1.127)
Train: 0 [  16/10009 (  0%)]  Loss:  6.995059 (6.9859)  Time: 0.275s,  464.95/s  (1.696s,   75.48/s)  LR: 1.000e-04  Data: 0.007 (1.061)
Train: 0 [  17/10009 (  0%)]  Loss:  7.021988 (6.9879)  Time: 0.321s,  398.48/s  (1.619s,   79.04/s)  LR: 1.000e-04  Data: 0.009 (1.003)
Train: 0 [  18/10009 (  0%)]  Loss:  6.987000 (6.9879)  Time: 0.263s,  485.99/s  (1.548s,   82.68/s)  LR: 1.000e-04  Data: 0.007 (0.951)
Train: 0 [  19/10009 (  0%)]  Loss:  6.984516 (6.9877)  Time: 4.581s,   27.94/s  (1.700s,   75.30/s)  LR: 1.000e-04  Data: 4.264 (1.116)
Train: 0 [  20/10009 (  0%)]  Loss:  7.003613 (6.9885)  Time: 0.325s,  393.59/s  (1.634s,   78.32/s)  LR: 1.000e-04  Data: 0.008 (1.063)
Train: 0 [  21/10009 (  0%)]  Loss:  6.994596 (6.9888)  Time: 0.350s,  365.81/s  (1.576s,   81.22/s)  LR: 1.000e-04  Data: 0.008 (1.015)
Train: 0 [  22/10009 (  0%)]  Loss:  7.004445 (6.9894)  Time: 0.272s,  471.29/s  (1.519s,   84.25/s)  LR: 1.000e-04  Data: 0.007 (0.972)
Train: 0 [  23/10009 (  0%)]  Loss:  6.987085 (6.9893)  Time: 4.845s,   26.42/s  (1.658s,   77.21/s)  LR: 1.000e-04  Data: 4.528 (1.120)
Train: 0 [  24/10009 (  0%)]  Loss:  7.008329 (6.9901)  Time: 0.573s,  223.21/s  (1.614s,   79.29/s)  LR: 1.000e-04  Data: 0.008 (1.075)
Train: 0 [  25/10009 (  0%)]  Loss:  7.068051 (6.9931)  Time: 0.306s,  418.09/s  (1.564s,   81.84/s)  LR: 1.000e-04  Data: 0.007 (1.034)
Train: 0 [  26/10009 (  0%)]  Loss:  6.998330 (6.9933)  Time: 0.272s,  470.19/s  (1.516s,   84.42/s)  LR: 1.000e-04  Data: 0.008 (0.996)
Train: 0 [  27/10009 (  0%)]  Loss:  6.937355 (6.9913)  Time: 5.142s,   24.90/s  (1.646s,   77.78/s)  LR: 1.000e-04  Data: 4.826 (1.133)
Train: 0 [  28/10009 (  0%)]  Loss:  6.951418 (6.9899)  Time: 0.625s,  204.80/s  (1.611s,   79.48/s)  LR: 1.000e-04  Data: 0.006 (1.094)
Train: 0 [  29/10009 (  0%)]  Loss:  6.983743 (6.9897)  Time: 0.272s,  471.32/s  (1.566s,   81.74/s)  LR: 1.000e-04  Data: 0.007 (1.058)
Train: 0 [  30/10009 (  0%)]  Loss:  6.992071 (6.9898)  Time: 0.265s,  482.64/s  (1.524s,   83.99/s)  LR: 1.000e-04  Data: 0.008 (1.024)
Train: 0 [  31/10009 (  0%)]  Loss:  6.953063 (6.9886)  Time: 4.581s,   27.94/s  (1.619s,   79.04/s)  LR: 1.000e-04  Data: 4.277 (1.126)
Train: 0 [  32/10009 (  0%)]  Loss:  6.979086 (6.9884)  Time: 0.272s,  469.91/s  (1.579s,   81.08/s)  LR: 1.000e-04  Data: 0.006 (1.092)
Train: 0 [  33/10009 (  0%)]  Loss:  7.003865 (6.9888)  Time: 0.512s,  249.90/s  (1.547s,   82.73/s)  LR: 1.000e-04  Data: 0.007 (1.060)
Train: 0 [  34/10009 (  0%)]  Loss:  6.976691 (6.9885)  Time: 0.265s,  483.91/s  (1.511s,   84.73/s)  LR: 1.000e-04  Data: 0.007 (1.030)
Train: 0 [  35/10009 (  0%)]  Loss:  7.057966 (6.9904)  Time: 4.847s,   26.41/s  (1.603s,   79.83/s)  LR: 1.000e-04  Data: 2.999 (1.084)
Train: 0 [  36/10009 (  0%)]  Loss:  6.938414 (6.9890)  Time: 0.642s,  199.48/s  (1.577s,   81.15/s)  LR: 1.000e-04  Data: 0.007 (1.055)
Train: 0 [  37/10009 (  0%)]  Loss:  6.990547 (6.9890)  Time: 0.411s,  311.79/s  (1.547s,   82.76/s)  LR: 1.000e-04  Data: 0.006 (1.028)
Train: 0 [  38/10009 (  0%)]  Loss:  6.978037 (6.9887)  Time: 0.267s,  478.70/s  (1.514s,   84.55/s)  LR: 1.000e-04  Data: 0.006 (1.002)
Train: 0 [  39/10009 (  0%)]  Loss:  7.020144 (6.9895)  Time: 5.485s,   23.34/s  (1.613s,   79.35/s)  LR: 1.000e-04  Data: 4.633 (1.092)
Train: 0 [  40/10009 (  0%)]  Loss:  6.914706 (6.9877)  Time: 0.785s,  163.05/s  (1.593s,   80.36/s)  LR: 1.000e-04  Data: 0.006 (1.066)
Train: 0 [  41/10009 (  0%)]  Loss:  7.001452 (6.9880)  Time: 0.265s,  482.96/s  (1.561s,   81.98/s)  LR: 1.000e-04  Data: 0.008 (1.041)
Train: 0 [  42/10009 (  0%)]  Loss:  7.003049 (6.9884)  Time: 0.263s,  487.49/s  (1.531s,   83.60/s)  LR: 1.000e-04  Data: 0.006 (1.017)
Train: 0 [  43/10009 (  0%)]  Loss:  7.032440 (6.9894)  Time: 3.995s,   32.04/s  (1.587s,   80.65/s)  LR: 1.000e-04  Data: 3.553 (1.074)
Train: 0 [  44/10009 (  0%)]  Loss:  6.992490 (6.9895)  Time: 0.915s,  139.82/s  (1.572s,   81.42/s)  LR: 1.000e-04  Data: 0.006 (1.050)
Train: 0 [  45/10009 (  0%)]  Loss:  7.035095 (6.9904)  Time: 0.267s,  478.99/s  (1.544s,   82.91/s)  LR: 1.000e-04  Data: 0.009 (1.028)
Train: 0 [  46/10009 (  0%)]  Loss:  7.010484 (6.9909)  Time: 0.262s,  487.73/s  (1.517s,   84.40/s)  LR: 1.000e-04  Data: 0.006 (1.006)
Train: 0 [  47/10009 (  0%)]  Loss:  6.966541 (6.9904)  Time: 4.819s,   26.56/s  (1.585s,   80.74/s)  LR: 1.000e-04  Data: 4.506 (1.079)
Train: 0 [  48/10009 (  0%)]  Loss:  6.995995 (6.9905)  Time: 0.363s,  352.65/s  (1.560s,   82.03/s)  LR: 1.000e-04  Data: 0.006 (1.057)
Train: 0 [  49/10009 (  0%)]  Loss:  7.000187 (6.9907)  Time: 0.716s,  178.75/s  (1.543s,   82.93/s)  LR: 1.000e-04  Data: 0.458 (1.045)
Train: 0 [  50/10009 (  0%)]  Loss:  6.926188 (6.9894)  Time: 0.264s,  485.45/s  (1.518s,   84.30/s)  LR: 1.000e-04  Data: 0.006 (1.025)
Train: 0 [  51/10009 (  1%)]  Loss:  7.000497 (6.9896)  Time: 4.564s,   28.04/s  (1.577s,   81.17/s)  LR: 1.000e-04  Data: 4.251 (1.087)
Train: 0 [  52/10009 (  1%)]  Loss:  6.954671 (6.9890)  Time: 0.267s,  480.26/s  (1.552s,   82.46/s)  LR: 1.000e-04  Data: 0.008 (1.066)
Train: 0 [  53/10009 (  1%)]  Loss:  6.999562 (6.9892)  Time: 0.421s,  303.78/s  (1.531s,   83.59/s)  LR: 1.000e-04  Data: 0.007 (1.047)
Train: 0 [  54/10009 (  1%)]  Loss:  7.023826 (6.9898)  Time: 0.265s,  483.54/s  (1.508s,   84.87/s)  LR: 1.000e-04  Data: 0.007 (1.028)
Train: 0 [  55/10009 (  1%)]  Loss:  6.936502 (6.9888)  Time: 4.576s,   27.97/s  (1.563s,   81.89/s)  LR: 1.000e-04  Data: 2.876 (1.061)
Train: 0 [  56/10009 (  1%)]  Loss:  7.015609 (6.9893)  Time: 0.272s,  470.31/s  (1.540s,   83.10/s)  LR: 1.000e-04  Data: 0.008 (1.042)
Train: 0 [  57/10009 (  1%)]  Loss:  6.999622 (6.9895)  Time: 0.369s,  347.03/s  (1.520s,   84.20/s)  LR: 1.000e-04  Data: 0.097 (1.026)
Train: 0 [  58/10009 (  1%)]  Loss:  6.964801 (6.9891)  Time: 0.266s,  481.79/s  (1.499s,   85.39/s)  LR: 1.000e-04  Data: 0.007 (1.009)
Train: 0 [  59/10009 (  1%)]  Loss:  6.931213 (6.9881)  Time: 3.619s,   35.36/s  (1.534s,   83.43/s)  LR: 1.000e-04  Data: 3.304 (1.047)
Train: 0 [  60/10009 (  1%)]  Loss:  6.963230 (6.9877)  Time: 0.271s,  471.63/s  (1.514s,   84.57/s)  LR: 1.000e-04  Data: 0.007 (1.030)
Train: 0 [  61/10009 (  1%)]  Loss:  6.983994 (6.9876)  Time: 1.521s,   84.13/s  (1.514s,   84.56/s)  LR: 1.000e-04  Data: 1.263 (1.034)
Train: 0 [  62/10009 (  1%)]  Loss:  7.024666 (6.9882)  Time: 0.264s,  484.71/s  (1.494s,   85.68/s)  LR: 1.000e-04  Data: 0.006 (1.018)
Train: 0 [  63/10009 (  1%)]  Loss:  6.944456 (6.9875)  Time: 3.677s,   34.81/s  (1.528s,   83.77/s)  LR: 1.000e-04  Data: 3.263 (1.053)
Train: 0 [  64/10009 (  1%)]  Loss:  6.977088 (6.9874)  Time: 0.273s,  469.31/s  (1.509s,   84.84/s)  LR: 1.000e-04  Data: 0.006 (1.036)
Train: 0 [  65/10009 (  1%)]  Loss:  6.967564 (6.9871)  Time: 2.041s,   62.70/s  (1.517s,   84.39/s)  LR: 1.000e-04  Data: 1.782 (1.048)
Train: 0 [  66/10009 (  1%)]  Loss:  6.989429 (6.9871)  Time: 0.263s,  485.91/s  (1.498s,   85.45/s)  LR: 1.000e-04  Data: 0.006 (1.032)
Train: 0 [  67/10009 (  1%)]  Loss:  6.996619 (6.9873)  Time: 4.006s,   31.95/s  (1.535s,   83.39/s)  LR: 1.000e-04  Data: 3.707 (1.072)
Train: 0 [  68/10009 (  1%)]  Loss:  6.963080 (6.9869)  Time: 1.149s,  111.38/s  (1.529s,   83.70/s)  LR: 1.000e-04  Data: 0.006 (1.056)
Train: 0 [  69/10009 (  1%)]  Loss:  6.987537 (6.9869)  Time: 1.083s,  118.23/s  (1.523s,   84.05/s)  LR: 1.000e-04  Data: 0.824 (1.053)
Train: 0 [  70/10009 (  1%)]  Loss:  6.942747 (6.9863)  Time: 0.268s,  477.96/s  (1.505s,   85.03/s)  LR: 1.000e-04  Data: 0.008 (1.038)
Train: 0 [  71/10009 (  1%)]  Loss:  6.920932 (6.9854)  Time: 2.870s,   44.59/s  (1.524s,   83.98/s)  LR: 1.000e-04  Data: 2.504 (1.058)
Train: 0 [  72/10009 (  1%)]  Loss:  6.944205 (6.9848)  Time: 0.548s,  233.71/s  (1.511s,   84.72/s)  LR: 1.000e-04  Data: 0.006 (1.044)
Train: 0 [  73/10009 (  1%)]  Loss:  6.947117 (6.9843)  Time: 2.089s,   61.29/s  (1.519s,   84.29/s)  LR: 1.000e-04  Data: 1.789 (1.054)
Train: 0 [  74/10009 (  1%)]  Loss:  6.958283 (6.9840)  Time: 0.264s,  485.73/s  (1.502s,   85.22/s)  LR: 1.000e-04  Data: 0.006 (1.040)
Train: 0 [  75/10009 (  1%)]  Loss:  6.902982 (6.9829)  Time: 2.859s,   44.76/s  (1.520s,   84.22/s)  LR: 1.000e-04  Data: 2.538 (1.060)
Train: 0 [  76/10009 (  1%)]  Loss:  7.008816 (6.9832)  Time: 0.838s,  152.78/s  (1.511s,   84.72/s)  LR: 1.000e-04  Data: 0.005 (1.046)
Train: 0 [  77/10009 (  1%)]  Loss:  7.013655 (6.9836)  Time: 2.202s,   58.12/s  (1.520s,   84.22/s)  LR: 1.000e-04  Data: 1.877 (1.057)
Train: 0 [  78/10009 (  1%)]  Loss:  6.996500 (6.9838)  Time: 0.268s,  478.06/s  (1.504s,   85.11/s)  LR: 1.000e-04  Data: 0.008 (1.044)
Train: 0 [  79/10009 (  1%)]  Loss:  6.979094 (6.9837)  Time: 1.838s,   69.64/s  (1.508s,   84.87/s)  LR: 1.000e-04  Data: 1.440 (1.048)
Train: 0 [  80/10009 (  1%)]  Loss:  7.023933 (6.9842)  Time: 0.832s,  153.93/s  (1.500s,   85.35/s)  LR: 1.000e-04  Data: 0.007 (1.036)
Train: 0 [  81/10009 (  1%)]  Loss:  7.058901 (6.9851)  Time: 2.635s,   48.58/s  (1.514s,   84.57/s)  LR: 1.000e-04  Data: 2.188 (1.050)
Train: 0 [  82/10009 (  1%)]  Loss:  7.002842 (6.9853)  Time: 0.265s,  482.29/s  (1.499s,   85.41/s)  LR: 1.000e-04  Data: 0.006 (1.037)
Train: 0 [  83/10009 (  1%)]  Loss:  7.008438 (6.9856)  Time: 2.320s,   55.17/s  (1.508s,   84.86/s)  LR: 1.000e-04  Data: 2.023 (1.049)
Train: 0 [  84/10009 (  1%)]  Loss:  6.999204 (6.9858)  Time: 0.725s,  176.44/s  (1.499s,   85.38/s)  LR: 1.000e-04  Data: 0.005 (1.037)
Train: 0 [  85/10009 (  1%)]  Loss:  7.077723 (6.9869)  Time: 0.883s,  145.00/s  (1.492s,   85.79/s)  LR: 1.000e-04  Data: 0.351 (1.029)
Train: 0 [  86/10009 (  1%)]  Loss:  6.917689 (6.9861)  Time: 0.264s,  485.71/s  (1.478s,   86.61/s)  LR: 1.000e-04  Data: 0.005 (1.017)
Train: 0 [  87/10009 (  1%)]  Loss:  6.994902 (6.9862)  Time: 2.715s,   47.14/s  (1.492s,   85.80/s)  LR: 1.000e-04  Data: 2.404 (1.033)
Train: 0 [  88/10009 (  1%)]  Loss:  6.924174 (6.9855)  Time: 1.847s,   69.31/s  (1.496s,   85.57/s)  LR: 1.000e-04  Data: 0.005 (1.021)
Train: 0 [  89/10009 (  1%)]  Loss:  6.968447 (6.9853)  Time: 1.020s,  125.46/s  (1.491s,   85.87/s)  LR: 1.000e-04  Data: 0.762 (1.018)
Train: 0 [  90/10009 (  1%)]  Loss:  7.015242 (6.9856)  Time: 0.262s,  487.73/s  (1.477s,   86.65/s)  LR: 1.000e-04  Data: 0.007 (1.007)
Train: 0 [  91/10009 (  1%)]  Loss:  6.990526 (6.9857)  Time: 2.342s,   54.65/s  (1.487s,   86.11/s)  LR: 1.000e-04  Data: 2.034 (1.018)
Train: 0 [  92/10009 (  1%)]  Loss:  6.936892 (6.9851)  Time: 2.375s,   53.88/s  (1.496s,   85.56/s)  LR: 1.000e-04  Data: 0.007 (1.007)
Train: 0 [  93/10009 (  1%)]  Loss:  6.921634 (6.9845)  Time: 0.713s,  179.58/s  (1.488s,   86.04/s)  LR: 1.000e-04  Data: 0.454 (1.001)
Train: 0 [  94/10009 (  1%)]  Loss:  7.019606 (6.9848)  Time: 0.268s,  478.33/s  (1.475s,   86.78/s)  LR: 1.000e-04  Data: 0.005 (0.991)
Train: 0 [  95/10009 (  1%)]  Loss:  6.964974 (6.9846)  Time: 2.162s,   59.22/s  (1.482s,   86.37/s)  LR: 1.000e-04  Data: 1.862 (1.000)
Train: 0 [  96/10009 (  1%)]  Loss:  6.956503 (6.9843)  Time: 2.958s,   43.28/s  (1.497s,   85.49/s)  LR: 1.000e-04  Data: 0.007 (0.990)
Train: 0 [  97/10009 (  1%)]  Loss:  6.944686 (6.9839)  Time: 0.267s,  479.42/s  (1.485s,   86.21/s)  LR: 1.000e-04  Data: 0.008 (0.980)
Train: 0 [  98/10009 (  1%)]  Loss:  6.973058 (6.9838)  Time: 0.264s,  484.44/s  (1.472s,   86.93/s)  LR: 1.000e-04  Data: 0.007 (0.970)
Train: 0 [  99/10009 (  1%)]  Loss:  6.949530 (6.9835)  Time: 0.617s,  207.37/s  (1.464s,   87.44/s)  LR: 1.000e-04  Data: 0.362 (0.964)
