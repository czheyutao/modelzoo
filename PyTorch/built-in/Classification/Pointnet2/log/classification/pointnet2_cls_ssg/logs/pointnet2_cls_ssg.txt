2025-03-03 06:54:49,107 - Model - INFO - PARAMETER ...
2025-03-03 06:54:49,107 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-03 06:54:49,107 - Model - INFO - Load dataset ...
2025-03-03 06:54:50,091 - Model - INFO - No existing model, starting training from scratch...
2025-03-03 06:54:50,091 - Model - INFO - Start training...
2025-03-03 06:54:50,091 - Model - INFO - Epoch 1 (1/200):
2025-03-03 06:55:51,797 - Model - INFO - PARAMETER ...
2025-03-03 06:55:51,797 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-03 06:55:51,797 - Model - INFO - Load dataset ...
2025-03-03 06:55:52,167 - Model - INFO - No existing model, starting training from scratch...
2025-03-03 06:55:52,167 - Model - INFO - Start training...
2025-03-03 06:55:52,167 - Model - INFO - Epoch 1 (1/200):
2025-03-03 06:55:53,493 - Model - INFO - Step 0 Loss: 3.610804319381714
2025-03-03 06:55:54,954 - Model - INFO - Step 1 Loss: 3.877805471420288
2025-03-03 06:55:56,490 - Model - INFO - Step 2 Loss: 3.635173797607422
2025-03-03 06:55:57,994 - Model - INFO - Step 3 Loss: 3.671630620956421
2025-03-03 06:55:59,402 - Model - INFO - Step 4 Loss: 3.6336510181427
2025-03-03 06:56:00,837 - Model - INFO - Step 5 Loss: 3.6210708618164062
2025-03-03 06:56:02,310 - Model - INFO - Step 6 Loss: 3.5295727252960205
2025-03-03 06:56:03,691 - Model - INFO - Step 7 Loss: 3.2351109981536865
2025-03-03 06:56:05,073 - Model - INFO - Step 8 Loss: 3.542797803878784
2025-03-03 06:56:06,517 - Model - INFO - Step 9 Loss: 3.4129083156585693
2025-03-03 06:56:07,960 - Model - INFO - Step 10 Loss: 3.763848304748535
2025-03-03 06:56:09,580 - Model - INFO - Step 11 Loss: 3.3600265979766846
2025-03-03 06:56:16,727 - Model - INFO - PARAMETER ...
2025-03-03 06:56:16,728 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-03 06:56:16,728 - Model - INFO - Load dataset ...
2025-03-03 06:56:17,094 - Model - INFO - No existing model, starting training from scratch...
2025-03-03 06:56:17,094 - Model - INFO - Start training...
2025-03-03 06:56:17,094 - Model - INFO - Epoch 1 (1/200):
2025-03-03 06:56:18,358 - Model - INFO - Step 0 Loss: 3.795356035232544
2025-03-03 06:56:19,721 - Model - INFO - Step 1 Loss: 3.600767135620117
2025-03-03 06:56:21,092 - Model - INFO - Step 2 Loss: 3.6160919666290283
2025-03-03 06:56:22,490 - Model - INFO - Step 3 Loss: 3.6493892669677734
2025-03-03 06:56:23,894 - Model - INFO - Step 4 Loss: 3.2984979152679443
2025-03-03 06:56:25,283 - Model - INFO - Step 5 Loss: 3.6929328441619873
2025-03-03 06:56:26,781 - Model - INFO - Step 6 Loss: 3.3375580310821533
2025-03-03 06:56:28,268 - Model - INFO - Step 7 Loss: 3.4251842498779297
2025-03-03 06:56:29,743 - Model - INFO - Step 8 Loss: 3.225466012954712
2025-03-03 06:56:31,244 - Model - INFO - Step 9 Loss: 3.4376189708709717
2025-03-03 06:56:32,763 - Model - INFO - Step 10 Loss: 2.962148427963257
2025-03-03 06:56:34,331 - Model - INFO - Step 11 Loss: 3.3755667209625244
2025-03-03 06:56:35,872 - Model - INFO - Step 12 Loss: 3.4299156665802
2025-03-03 06:56:37,419 - Model - INFO - Step 13 Loss: 3.1243937015533447
2025-03-03 06:56:38,998 - Model - INFO - Step 14 Loss: 3.0354690551757812
2025-03-03 06:56:40,622 - Model - INFO - Step 15 Loss: 3.0196733474731445
2025-03-03 06:56:42,179 - Model - INFO - Step 16 Loss: 3.4762983322143555
2025-03-03 06:56:43,731 - Model - INFO - Step 17 Loss: 3.0732829570770264
2025-03-03 06:56:45,336 - Model - INFO - Step 18 Loss: 2.682220458984375
2025-03-03 06:56:46,902 - Model - INFO - Step 19 Loss: 3.102647542953491
2025-03-03 06:56:48,460 - Model - INFO - Step 20 Loss: 3.3714711666107178
2025-03-03 06:56:50,033 - Model - INFO - Step 21 Loss: 3.2951440811157227
2025-03-03 06:56:51,624 - Model - INFO - Step 22 Loss: 3.5088253021240234
2025-03-03 06:56:53,341 - Model - INFO - Step 23 Loss: 3.595576286315918
2025-03-03 06:56:55,017 - Model - INFO - Step 24 Loss: 2.9301929473876953
2025-03-03 06:56:56,649 - Model - INFO - Step 25 Loss: 3.053960084915161
2025-03-03 06:56:58,317 - Model - INFO - Step 26 Loss: 3.266437530517578
2025-03-03 06:56:59,945 - Model - INFO - Step 27 Loss: 3.463470220565796
2025-03-03 06:57:01,593 - Model - INFO - Step 28 Loss: 3.280283212661743
2025-03-03 06:57:03,264 - Model - INFO - Step 29 Loss: 3.0560379028320312
2025-03-03 06:57:04,959 - Model - INFO - Step 30 Loss: 3.199723243713379
2025-03-03 06:57:06,653 - Model - INFO - Step 31 Loss: 2.646998167037964
2025-03-03 06:57:08,444 - Model - INFO - Step 32 Loss: 2.683345079421997
2025-03-03 06:57:10,161 - Model - INFO - Step 33 Loss: 3.091992139816284
2025-03-03 06:57:11,719 - Model - INFO - Step 34 Loss: 3.303367853164673
2025-03-03 06:57:13,293 - Model - INFO - Step 35 Loss: 2.556920289993286
2025-03-03 06:57:14,894 - Model - INFO - Step 36 Loss: 2.8978288173675537
2025-03-03 06:57:16,584 - Model - INFO - Step 37 Loss: 2.974224328994751
2025-03-03 06:57:18,202 - Model - INFO - Step 38 Loss: 2.2002599239349365
2025-03-03 06:57:19,812 - Model - INFO - Step 39 Loss: 2.324223756790161
2025-03-03 06:57:21,456 - Model - INFO - Step 40 Loss: 2.6542916297912598
2025-03-03 06:57:23,111 - Model - INFO - Step 41 Loss: 3.387317657470703
2025-03-03 06:57:24,801 - Model - INFO - Step 42 Loss: 2.111894369125366
2025-03-03 06:57:26,494 - Model - INFO - Step 43 Loss: 2.7160511016845703
2025-03-03 06:57:28,211 - Model - INFO - Step 44 Loss: 2.5875930786132812
2025-03-03 06:57:29,942 - Model - INFO - Step 45 Loss: 2.4112846851348877
2025-03-03 06:57:31,683 - Model - INFO - Step 46 Loss: 2.3980863094329834
2025-03-03 06:57:33,447 - Model - INFO - Step 47 Loss: 2.5891542434692383
2025-03-03 06:57:35,227 - Model - INFO - Step 48 Loss: 2.7368171215057373
2025-03-03 06:57:36,963 - Model - INFO - Step 49 Loss: 2.5938127040863037
2025-03-03 06:57:38,784 - Model - INFO - Step 50 Loss: 2.9452903270721436
2025-03-03 06:57:40,535 - Model - INFO - Step 51 Loss: 2.295820951461792
2025-03-03 06:57:42,279 - Model - INFO - Step 52 Loss: 2.563767910003662
2025-03-03 06:57:44,103 - Model - INFO - Step 53 Loss: 2.499924898147583
2025-03-03 06:57:45,875 - Model - INFO - Step 54 Loss: 2.4398629665374756
2025-03-03 06:57:47,594 - Model - INFO - Step 55 Loss: 2.5734498500823975
2025-03-03 06:57:49,325 - Model - INFO - Step 56 Loss: 2.219877004623413
2025-03-03 06:57:51,058 - Model - INFO - Step 57 Loss: 2.366335391998291
2025-03-03 06:57:52,807 - Model - INFO - Step 58 Loss: 2.233367681503296
2025-03-03 06:57:54,559 - Model - INFO - Step 59 Loss: 2.6522881984710693
2025-03-03 06:57:56,388 - Model - INFO - Step 60 Loss: 2.5179083347320557
2025-03-03 06:57:58,162 - Model - INFO - Step 61 Loss: 2.307035207748413
2025-03-03 06:57:59,916 - Model - INFO - Step 62 Loss: 2.344716787338257
2025-03-03 06:58:01,659 - Model - INFO - Step 63 Loss: 2.557488441467285
2025-03-03 06:58:03,381 - Model - INFO - Step 64 Loss: 2.335766077041626
2025-03-03 06:58:05,089 - Model - INFO - Step 65 Loss: 2.062700033187866
2025-03-03 06:58:06,741 - Model - INFO - Step 66 Loss: 2.346846580505371
2025-03-03 06:58:08,286 - Model - INFO - Step 67 Loss: 2.158917188644409
2025-03-03 06:58:09,850 - Model - INFO - Step 68 Loss: 2.944883346557617
2025-03-03 06:58:11,446 - Model - INFO - Step 69 Loss: 2.656040906906128
2025-03-03 06:58:13,061 - Model - INFO - Step 70 Loss: 2.2442991733551025
2025-03-03 06:58:14,676 - Model - INFO - Step 71 Loss: 2.0666630268096924
2025-03-03 06:58:16,311 - Model - INFO - Step 72 Loss: 1.7625523805618286
2025-03-03 06:58:17,951 - Model - INFO - Step 73 Loss: 2.905729293823242
2025-03-03 06:58:19,638 - Model - INFO - Step 74 Loss: 2.503728151321411
2025-03-03 06:58:21,386 - Model - INFO - Step 75 Loss: 2.208629846572876
2025-03-03 06:58:23,087 - Model - INFO - Step 76 Loss: 2.734463930130005
2025-03-03 06:58:24,804 - Model - INFO - Step 77 Loss: 2.2073616981506348
2025-03-03 06:58:26,502 - Model - INFO - Step 78 Loss: 2.2057392597198486
2025-03-03 06:58:28,229 - Model - INFO - Step 79 Loss: 2.264841079711914
2025-03-03 06:58:29,912 - Model - INFO - Step 80 Loss: 1.965825080871582
2025-03-03 06:58:31,680 - Model - INFO - Step 81 Loss: 1.684469223022461
2025-03-03 06:58:33,354 - Model - INFO - Step 82 Loss: 1.639520525932312
2025-03-03 06:58:35,005 - Model - INFO - Step 83 Loss: 2.5461597442626953
2025-03-03 06:58:36,697 - Model - INFO - Step 84 Loss: 2.0795679092407227
2025-03-03 06:58:38,406 - Model - INFO - Step 85 Loss: 2.661050319671631
2025-03-03 06:58:40,127 - Model - INFO - Step 86 Loss: 2.7319297790527344
2025-03-03 06:58:41,943 - Model - INFO - Step 87 Loss: 1.9267116785049438
2025-03-03 06:58:43,730 - Model - INFO - Step 88 Loss: 2.3616597652435303
2025-03-03 06:58:45,496 - Model - INFO - Step 89 Loss: 1.8762558698654175
2025-03-03 06:58:47,255 - Model - INFO - Step 90 Loss: 2.11845064163208
2025-03-03 06:58:49,046 - Model - INFO - Step 91 Loss: 2.132833242416382
2025-03-03 06:58:50,837 - Model - INFO - Step 92 Loss: 2.348109483718872
2025-03-03 06:58:52,617 - Model - INFO - Step 93 Loss: 1.9271702766418457
2025-03-03 06:58:54,477 - Model - INFO - Step 94 Loss: 2.450307607650757
2025-03-03 06:58:56,237 - Model - INFO - Step 95 Loss: 2.2963106632232666
2025-03-03 06:58:58,000 - Model - INFO - Step 96 Loss: 2.63293719291687
2025-03-03 06:58:59,786 - Model - INFO - Step 97 Loss: 1.96992826461792
2025-03-03 06:59:01,566 - Model - INFO - Step 98 Loss: 2.121609926223755
2025-03-03 06:59:03,365 - Model - INFO - Step 99 Loss: 2.3454430103302
2025-03-03 06:59:05,159 - Model - INFO - Step 100 Loss: 2.0373852252960205
2025-03-03 06:59:06,938 - Model - INFO - Step 101 Loss: 2.230783700942993
2025-03-03 06:59:08,721 - Model - INFO - Step 102 Loss: 1.743256688117981
2025-03-03 06:59:10,593 - Model - INFO - Step 103 Loss: 2.454340934753418
2025-03-03 06:59:12,415 - Model - INFO - Step 104 Loss: 2.192410945892334
2025-03-03 06:59:14,148 - Model - INFO - Step 105 Loss: 2.4255709648132324
2025-03-03 06:59:15,893 - Model - INFO - Step 106 Loss: 1.8668261766433716
2025-03-03 06:59:17,660 - Model - INFO - Step 107 Loss: 2.413891315460205
2025-03-03 06:59:19,443 - Model - INFO - Step 108 Loss: 2.0594584941864014
2025-03-03 06:59:21,233 - Model - INFO - Step 109 Loss: 2.2904367446899414
2025-03-03 06:59:23,013 - Model - INFO - Step 110 Loss: 2.205673933029175
2025-03-03 06:59:24,847 - Model - INFO - Step 111 Loss: 2.2343549728393555
2025-03-03 06:59:26,711 - Model - INFO - Step 112 Loss: 2.1594836711883545
2025-03-03 06:59:28,543 - Model - INFO - Step 113 Loss: 2.118910551071167
2025-03-03 06:59:30,349 - Model - INFO - Step 114 Loss: 1.7397128343582153
2025-03-03 06:59:32,237 - Model - INFO - Step 115 Loss: 1.8965121507644653
2025-03-03 06:59:34,085 - Model - INFO - Step 116 Loss: 1.5527396202087402
2025-03-03 06:59:35,880 - Model - INFO - Step 117 Loss: 2.169055461883545
2025-03-03 06:59:37,687 - Model - INFO - Step 118 Loss: 2.4169390201568604
2025-03-03 06:59:39,502 - Model - INFO - Step 119 Loss: 1.8158289194107056
2025-03-03 06:59:41,277 - Model - INFO - Step 120 Loss: 2.2683050632476807
2025-03-03 06:59:43,076 - Model - INFO - Step 121 Loss: 1.7995014190673828
2025-03-03 06:59:44,868 - Model - INFO - Step 122 Loss: 2.62384295463562
2025-03-03 06:59:46,698 - Model - INFO - Step 123 Loss: 2.41042160987854
2025-03-03 06:59:48,491 - Model - INFO - Step 124 Loss: 2.533534288406372
2025-03-03 06:59:50,152 - Model - INFO - Step 125 Loss: 1.6269354820251465
2025-03-03 06:59:51,673 - Model - INFO - Step 126 Loss: 1.4379545450210571
2025-03-03 06:59:53,340 - Model - INFO - Step 127 Loss: 2.244837522506714
2025-03-03 06:59:55,051 - Model - INFO - Step 128 Loss: 2.011183500289917
2025-03-03 06:59:56,739 - Model - INFO - Step 129 Loss: 1.753130316734314
2025-03-03 06:59:58,429 - Model - INFO - Step 130 Loss: 1.539162278175354
2025-03-03 07:00:00,158 - Model - INFO - Step 131 Loss: 1.7519326210021973
2025-03-03 07:00:01,899 - Model - INFO - Step 132 Loss: 1.7299846410751343
2025-03-03 07:00:03,653 - Model - INFO - Step 133 Loss: 2.006814479827881
2025-03-03 07:00:05,423 - Model - INFO - Step 134 Loss: 2.417276620864868
2025-03-03 07:00:07,189 - Model - INFO - Step 135 Loss: 2.091322183609009
2025-03-03 07:00:09,009 - Model - INFO - Step 136 Loss: 2.4766576290130615
2025-03-03 07:00:10,774 - Model - INFO - Step 137 Loss: 2.797764539718628
2025-03-03 07:11:54,417 - Model - INFO - PARAMETER ...
2025-03-03 07:11:54,417 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-03 07:11:54,417 - Model - INFO - Load dataset ...
2025-03-03 07:11:54,760 - Model - INFO - No existing model, starting training from scratch...
2025-03-03 07:11:54,760 - Model - INFO - Start training...
2025-03-03 07:11:54,760 - Model - INFO - Epoch 1 (1/200):
2025-03-03 07:11:56,182 - Model - INFO - Step 0 Loss: 3.8990933895111084
2025-03-03 07:11:57,697 - Model - INFO - Step 1 Loss: 3.697568893432617
2025-03-03 07:11:59,394 - Model - INFO - Step 2 Loss: 3.6724300384521484
2025-03-03 07:12:01,070 - Model - INFO - Step 3 Loss: 3.5897610187530518
2025-03-03 07:12:02,677 - Model - INFO - Step 4 Loss: 3.5555248260498047
2025-03-03 07:12:04,296 - Model - INFO - Step 5 Loss: 3.414658546447754
2025-03-03 07:12:05,934 - Model - INFO - Step 6 Loss: 3.39731502532959
2025-03-03 07:12:07,550 - Model - INFO - Step 7 Loss: 3.263286828994751
2025-03-03 07:12:09,179 - Model - INFO - Step 8 Loss: 3.3016576766967773
2025-03-03 07:12:10,900 - Model - INFO - Step 9 Loss: 3.2113535404205322
2025-03-03 07:12:12,993 - Model - INFO - Step 10 Loss: 3.06876540184021
2025-03-03 07:12:15,186 - Model - INFO - Step 11 Loss: 3.220958948135376
2025-03-03 07:12:17,356 - Model - INFO - Step 12 Loss: 3.709411859512329
2025-03-03 07:12:19,549 - Model - INFO - Step 13 Loss: 3.284930467605591
2025-03-03 07:12:21,751 - Model - INFO - Step 14 Loss: 3.310574769973755
2025-03-03 07:12:23,972 - Model - INFO - Step 15 Loss: 3.482065439224243
2025-03-03 07:12:26,186 - Model - INFO - Step 16 Loss: 2.761087417602539
2025-03-03 07:12:28,039 - Model - INFO - Step 17 Loss: 2.924677848815918
2025-03-03 07:12:29,802 - Model - INFO - Step 18 Loss: 3.2676732540130615
2025-03-03 07:12:31,522 - Model - INFO - Step 19 Loss: 2.925593614578247
2025-03-03 07:12:33,143 - Model - INFO - Step 20 Loss: 3.5249574184417725
2025-03-03 07:12:34,758 - Model - INFO - Step 21 Loss: 3.5437676906585693
2025-03-03 07:12:36,360 - Model - INFO - Step 22 Loss: 3.023223638534546
2025-03-03 07:12:37,942 - Model - INFO - Step 23 Loss: 3.147407293319702
2025-03-03 07:12:39,530 - Model - INFO - Step 24 Loss: 2.9370975494384766
2025-03-03 07:12:41,281 - Model - INFO - Step 25 Loss: 3.14908766746521
2025-03-03 07:12:42,865 - Model - INFO - Step 26 Loss: 3.0291059017181396
2025-03-03 07:12:44,761 - Model - INFO - Step 27 Loss: 3.207322120666504
2025-03-03 07:12:46,427 - Model - INFO - Step 28 Loss: 3.3150882720947266
2025-03-03 07:12:48,521 - Model - INFO - Step 29 Loss: 3.115854263305664
2025-03-03 07:12:50,270 - Model - INFO - Step 30 Loss: 3.118312120437622
2025-03-03 07:12:52,004 - Model - INFO - Step 31 Loss: 3.1322879791259766
2025-03-03 07:12:53,586 - Model - INFO - Step 32 Loss: 2.9040985107421875
2025-03-03 07:12:55,307 - Model - INFO - Step 33 Loss: 2.961771011352539
2025-03-03 07:12:56,919 - Model - INFO - Step 34 Loss: 3.436283826828003
2025-03-03 07:12:58,493 - Model - INFO - Step 35 Loss: 3.1691360473632812
2025-03-03 07:13:00,125 - Model - INFO - Step 36 Loss: 3.083231210708618
2025-03-03 07:13:01,710 - Model - INFO - Step 37 Loss: 2.8414628505706787
2025-03-03 07:13:03,527 - Model - INFO - Step 38 Loss: 3.1540515422821045
2025-03-03 07:13:05,127 - Model - INFO - Step 39 Loss: 3.1441757678985596
2025-03-03 07:13:06,942 - Model - INFO - Step 40 Loss: 2.5525147914886475
2025-03-03 07:13:08,664 - Model - INFO - Step 41 Loss: 2.947209119796753
2025-03-03 07:13:10,286 - Model - INFO - Step 42 Loss: 2.7303953170776367
2025-03-03 07:13:11,889 - Model - INFO - Step 43 Loss: 2.8023593425750732
2025-03-03 07:13:13,505 - Model - INFO - Step 44 Loss: 2.6187903881073
2025-03-03 07:13:15,067 - Model - INFO - Step 45 Loss: 2.7968761920928955
2025-03-03 07:13:16,913 - Model - INFO - Step 46 Loss: 2.9107656478881836
2025-03-03 07:13:18,643 - Model - INFO - Step 47 Loss: 2.443676233291626
2025-03-03 07:13:20,278 - Model - INFO - Step 48 Loss: 2.262718439102173
2025-03-03 07:13:21,894 - Model - INFO - Step 49 Loss: 2.694012403488159
2025-03-03 07:13:23,535 - Model - INFO - Step 50 Loss: 2.567106008529663
2025-03-03 07:13:25,140 - Model - INFO - Step 51 Loss: 2.239002227783203
2025-03-03 07:13:26,796 - Model - INFO - Step 52 Loss: 2.425065517425537
2025-03-03 07:13:28,485 - Model - INFO - Step 53 Loss: 2.765458822250366
2025-03-03 07:13:30,112 - Model - INFO - Step 54 Loss: 2.32629656791687
2025-03-03 07:13:31,837 - Model - INFO - Step 55 Loss: 2.555677652359009
2025-03-03 07:13:33,456 - Model - INFO - Step 56 Loss: 2.796706199645996
2025-03-03 07:13:35,251 - Model - INFO - Step 57 Loss: 2.2599985599517822
2025-03-03 07:13:36,970 - Model - INFO - Step 58 Loss: 2.4781081676483154
2025-03-03 07:13:38,639 - Model - INFO - Step 59 Loss: 2.475153684616089
2025-03-03 07:13:40,271 - Model - INFO - Step 60 Loss: 2.5142605304718018
2025-03-03 07:13:41,858 - Model - INFO - Step 61 Loss: 2.6720306873321533
2025-03-03 07:13:43,451 - Model - INFO - Step 62 Loss: 2.341338872909546
2025-03-03 07:13:45,191 - Model - INFO - Step 63 Loss: 2.208491563796997
2025-03-03 07:13:46,835 - Model - INFO - Step 64 Loss: 2.731048822402954
2025-03-03 07:13:48,449 - Model - INFO - Step 65 Loss: 2.2540953159332275
2025-03-03 07:13:50,165 - Model - INFO - Step 66 Loss: 2.8265063762664795
2025-03-03 07:13:51,828 - Model - INFO - Step 67 Loss: 2.7546708583831787
2025-03-03 07:13:53,500 - Model - INFO - Step 68 Loss: 2.2683207988739014
2025-03-03 07:13:55,092 - Model - INFO - Step 69 Loss: 2.3401472568511963
2025-03-03 07:13:56,843 - Model - INFO - Step 70 Loss: 2.0219779014587402
2025-03-03 07:13:58,456 - Model - INFO - Step 71 Loss: 2.559635639190674
2025-03-03 07:14:00,172 - Model - INFO - Step 72 Loss: 2.737523078918457
2025-03-03 07:14:01,814 - Model - INFO - Step 73 Loss: 2.3979508876800537
2025-03-03 07:14:03,481 - Model - INFO - Step 74 Loss: 2.707016706466675
2025-03-03 07:14:05,083 - Model - INFO - Step 75 Loss: 2.021080255508423
2025-03-03 07:14:06,698 - Model - INFO - Step 76 Loss: 2.2096214294433594
2025-03-03 07:14:08,374 - Model - INFO - Step 77 Loss: 2.3840179443359375
2025-03-03 07:14:10,108 - Model - INFO - Step 78 Loss: 2.0431442260742188
2025-03-03 07:14:11,765 - Model - INFO - Step 79 Loss: 2.6369035243988037
2025-03-03 07:14:13,435 - Model - INFO - Step 80 Loss: 2.361677408218384
2025-03-03 07:14:15,154 - Model - INFO - Step 81 Loss: 2.581540822982788
2025-03-03 07:14:16,837 - Model - INFO - Step 82 Loss: 2.2634620666503906
2025-03-03 07:14:18,541 - Model - INFO - Step 83 Loss: 2.4582810401916504
2025-03-03 07:14:20,241 - Model - INFO - Step 84 Loss: 2.809032440185547
2025-03-03 07:14:22,055 - Model - INFO - Step 85 Loss: 2.956796407699585
2025-03-03 07:14:23,746 - Model - INFO - Step 86 Loss: 2.6930081844329834
2025-03-03 07:14:25,492 - Model - INFO - Step 87 Loss: 2.428753137588501
2025-03-03 07:14:27,229 - Model - INFO - Step 88 Loss: 2.1583588123321533
2025-03-03 07:14:28,854 - Model - INFO - Step 89 Loss: 2.125633955001831
2025-03-03 07:14:30,796 - Model - INFO - Step 90 Loss: 2.217243194580078
2025-03-03 07:14:32,422 - Model - INFO - Step 91 Loss: 2.1036128997802734
2025-03-03 07:14:34,029 - Model - INFO - Step 92 Loss: 2.039114236831665
2025-03-03 07:14:35,824 - Model - INFO - Step 93 Loss: 2.3251092433929443
2025-03-03 07:14:37,499 - Model - INFO - Step 94 Loss: 2.5329625606536865
2025-03-03 07:14:39,194 - Model - INFO - Step 95 Loss: 2.412109613418579
2025-03-03 07:14:40,874 - Model - INFO - Step 96 Loss: 2.3505091667175293
2025-03-03 07:14:42,594 - Model - INFO - Step 97 Loss: 1.6234036684036255
2025-03-03 07:14:44,579 - Model - INFO - Step 98 Loss: 1.6242742538452148
2025-03-03 07:14:46,619 - Model - INFO - Step 99 Loss: 2.328303575515747
2025-03-03 07:14:48,709 - Model - INFO - Step 100 Loss: 2.0749239921569824
2025-03-03 07:14:50,678 - Model - INFO - Step 101 Loss: 1.975422978401184
2025-03-03 07:14:52,736 - Model - INFO - Step 102 Loss: 2.283066987991333
2025-03-03 07:14:54,765 - Model - INFO - Step 103 Loss: 2.5926945209503174
2025-03-03 07:28:48,891 - Model - INFO - PARAMETER ...
2025-03-03 07:28:48,891 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-03 07:28:48,891 - Model - INFO - Load dataset ...
2025-03-03 07:28:49,253 - Model - INFO - No existing model, starting training from scratch...
2025-03-03 07:28:49,253 - Model - INFO - Start training...
2025-03-03 07:28:49,253 - Model - INFO - Epoch 1 (1/200):
2025-03-03 07:28:50,676 - Model - INFO - Step 0 Loss: 3.729295492172241
2025-03-03 07:28:52,434 - Model - INFO - Step 1 Loss: 3.8602211475372314
2025-03-03 07:28:54,359 - Model - INFO - Step 2 Loss: 3.8107750415802
2025-03-03 07:28:56,318 - Model - INFO - Step 3 Loss: 3.500507116317749
2025-03-03 07:28:57,636 - Model - INFO - Step 4 Loss: 3.571739435195923
2025-03-03 07:28:59,031 - Model - INFO - Step 5 Loss: 3.6171960830688477
2025-03-03 07:29:00,390 - Model - INFO - Step 6 Loss: 3.4797232151031494
2025-03-03 07:29:01,776 - Model - INFO - Step 7 Loss: 3.678462028503418
2025-03-03 07:29:03,205 - Model - INFO - Step 8 Loss: 3.2270138263702393
2025-03-03 07:29:04,633 - Model - INFO - Step 9 Loss: 3.460850715637207
2025-03-03 07:29:06,011 - Model - INFO - Step 10 Loss: 3.1948108673095703
2025-03-03 07:29:07,416 - Model - INFO - Step 11 Loss: 3.7302732467651367
2025-03-03 07:29:08,812 - Model - INFO - Step 12 Loss: 3.42745304107666
2025-03-03 07:29:10,210 - Model - INFO - Step 13 Loss: 3.201667070388794
2025-03-03 07:29:11,606 - Model - INFO - Step 14 Loss: 3.31084942817688
2025-03-03 07:29:12,984 - Model - INFO - Step 15 Loss: 3.0547103881835938
2025-03-03 07:29:14,353 - Model - INFO - Step 16 Loss: 3.17292857170105
2025-03-03 07:29:15,789 - Model - INFO - Step 17 Loss: 3.2756996154785156
2025-03-03 07:29:17,273 - Model - INFO - Step 18 Loss: 2.8101768493652344
2025-03-03 07:29:18,782 - Model - INFO - Step 19 Loss: 3.1172492504119873
2025-03-03 07:29:20,230 - Model - INFO - Step 20 Loss: 2.9891204833984375
2025-03-03 07:29:21,599 - Model - INFO - Step 21 Loss: 3.3876097202301025
2025-03-03 07:29:23,051 - Model - INFO - Step 22 Loss: 3.191335678100586
2025-03-03 07:29:24,595 - Model - INFO - Step 23 Loss: 3.1575756072998047
2025-03-03 07:29:26,293 - Model - INFO - Step 24 Loss: 2.9675543308258057
2025-03-03 07:29:27,815 - Model - INFO - Step 25 Loss: 2.6507952213287354
2025-03-03 07:29:29,251 - Model - INFO - Step 26 Loss: 3.1491963863372803
2025-03-03 07:29:30,714 - Model - INFO - Step 27 Loss: 3.0029067993164062
2025-03-03 07:29:32,177 - Model - INFO - Step 28 Loss: 2.5621609687805176
2025-03-03 07:29:33,528 - Model - INFO - Step 29 Loss: 2.6954517364501953
2025-03-03 07:29:34,929 - Model - INFO - Step 30 Loss: 3.3596792221069336
2025-03-03 07:29:36,327 - Model - INFO - Step 31 Loss: 2.4839885234832764
2025-03-03 07:29:37,734 - Model - INFO - Step 32 Loss: 3.065277099609375
2025-03-03 07:29:39,189 - Model - INFO - Step 33 Loss: 3.0247669219970703
2025-03-03 07:29:40,819 - Model - INFO - Step 34 Loss: 2.518963098526001
2025-03-03 07:29:42,630 - Model - INFO - Step 35 Loss: 2.911778450012207
2025-03-03 07:29:44,471 - Model - INFO - Step 36 Loss: 3.1151084899902344
2025-03-03 07:29:46,103 - Model - INFO - Step 37 Loss: 2.2408061027526855
2025-03-03 07:29:47,549 - Model - INFO - Step 38 Loss: 2.5902152061462402
2025-03-03 07:29:49,273 - Model - INFO - Step 39 Loss: 2.8557164669036865
2025-03-03 07:29:51,092 - Model - INFO - Step 40 Loss: 2.634911298751831
2025-03-03 07:29:52,995 - Model - INFO - Step 41 Loss: 2.503429412841797
2025-03-03 07:29:54,890 - Model - INFO - Step 42 Loss: 2.926467180252075
2025-03-03 07:29:56,343 - Model - INFO - Step 43 Loss: 2.6214635372161865
2025-03-03 07:29:57,844 - Model - INFO - Step 44 Loss: 2.819887161254883
2025-03-03 07:29:59,354 - Model - INFO - Step 45 Loss: 2.7894022464752197
2025-03-03 07:30:00,876 - Model - INFO - Step 46 Loss: 2.803598403930664
2025-03-03 07:30:02,333 - Model - INFO - Step 47 Loss: 2.8914220333099365
2025-03-03 07:30:03,662 - Model - INFO - Step 48 Loss: 2.5088250637054443
2025-03-03 07:30:05,179 - Model - INFO - Step 49 Loss: 2.3801047801971436
2025-03-03 07:30:06,613 - Model - INFO - Step 50 Loss: 2.562429189682007
2025-03-03 07:30:08,031 - Model - INFO - Step 51 Loss: 2.5031425952911377
2025-03-03 07:30:09,475 - Model - INFO - Step 52 Loss: 2.1454861164093018
2025-03-03 07:30:10,809 - Model - INFO - Step 53 Loss: 2.640247106552124
2025-03-03 07:30:12,240 - Model - INFO - Step 54 Loss: 2.4548585414886475
2025-03-03 07:30:13,692 - Model - INFO - Step 55 Loss: 2.340167760848999
2025-03-03 07:30:15,206 - Model - INFO - Step 56 Loss: 2.6196963787078857
2025-03-03 07:30:16,788 - Model - INFO - Step 57 Loss: 2.6104772090911865
2025-03-03 07:30:18,387 - Model - INFO - Step 58 Loss: 2.220649003982544
2025-03-03 07:30:20,014 - Model - INFO - Step 59 Loss: 2.336885690689087
2025-03-03 07:30:21,701 - Model - INFO - Step 60 Loss: 2.295504331588745
2025-03-03 07:30:23,405 - Model - INFO - Step 61 Loss: 2.479541063308716
2025-03-03 07:30:25,166 - Model - INFO - Step 62 Loss: 2.2834622859954834
2025-03-03 07:30:26,701 - Model - INFO - Step 63 Loss: 2.502077579498291
2025-03-03 07:30:28,042 - Model - INFO - Step 64 Loss: 2.219625234603882
2025-03-03 07:30:29,374 - Model - INFO - Step 65 Loss: 2.3138277530670166
2025-03-03 07:30:30,755 - Model - INFO - Step 66 Loss: 1.642878532409668
2025-03-03 07:30:32,605 - Model - INFO - Step 67 Loss: 2.528832197189331
2025-03-03 07:30:34,773 - Model - INFO - Step 68 Loss: 1.9089137315750122
2025-03-03 07:30:36,502 - Model - INFO - Step 69 Loss: 2.038503885269165
2025-03-03 07:30:37,887 - Model - INFO - Step 70 Loss: 2.6513078212738037
2025-03-03 07:30:39,628 - Model - INFO - Step 71 Loss: 2.2218639850616455
2025-03-03 07:30:41,431 - Model - INFO - Step 72 Loss: 2.080514430999756
2025-03-03 07:30:43,282 - Model - INFO - Step 73 Loss: 2.2823612689971924
2025-03-03 07:30:45,252 - Model - INFO - Step 74 Loss: 2.0086238384246826
2025-03-03 07:30:47,361 - Model - INFO - Step 75 Loss: 2.2318179607391357
2025-03-03 07:30:49,442 - Model - INFO - Step 76 Loss: 2.417833089828491
2025-03-03 07:30:51,535 - Model - INFO - Step 77 Loss: 2.3877475261688232
2025-03-03 07:30:53,159 - Model - INFO - Step 78 Loss: 2.1148836612701416
2025-03-03 07:30:54,709 - Model - INFO - Step 79 Loss: 2.2728304862976074
2025-03-03 07:30:56,212 - Model - INFO - Step 80 Loss: 2.1419763565063477
2025-03-03 07:30:57,674 - Model - INFO - Step 81 Loss: 2.3860347270965576
2025-03-03 07:30:59,181 - Model - INFO - Step 82 Loss: 2.5090184211730957
2025-03-03 07:31:00,576 - Model - INFO - Step 83 Loss: 1.5909472703933716
2025-03-03 07:31:01,903 - Model - INFO - Step 84 Loss: 2.333852529525757
2025-03-03 07:31:03,274 - Model - INFO - Step 85 Loss: 1.8949118852615356
2025-03-03 07:31:04,644 - Model - INFO - Step 86 Loss: 2.1142895221710205
2025-03-03 07:31:06,065 - Model - INFO - Step 87 Loss: 2.2852962017059326
2025-03-03 07:31:07,520 - Model - INFO - Step 88 Loss: 1.9164646863937378
2025-03-03 07:31:08,844 - Model - INFO - Step 89 Loss: 2.240372657775879
2025-03-03 07:31:10,170 - Model - INFO - Step 90 Loss: 2.531879186630249
2025-03-03 07:31:11,488 - Model - INFO - Step 91 Loss: 2.047325849533081
2025-03-03 07:31:12,860 - Model - INFO - Step 92 Loss: 2.1243932247161865
2025-03-03 07:31:14,295 - Model - INFO - Step 93 Loss: 1.890170693397522
2025-03-03 07:31:15,768 - Model - INFO - Step 94 Loss: 2.5356619358062744
2025-03-03 07:31:17,293 - Model - INFO - Step 95 Loss: 2.2412004470825195
2025-03-03 07:31:18,621 - Model - INFO - Step 96 Loss: 1.6241707801818848
2025-03-03 07:31:20,015 - Model - INFO - Step 97 Loss: 2.20719051361084
2025-03-03 07:31:21,425 - Model - INFO - Step 98 Loss: 2.1997995376586914
2025-03-03 07:31:22,885 - Model - INFO - Step 99 Loss: 1.9557737112045288
2025-03-03 07:31:24,396 - Model - INFO - Step 100 Loss: 1.676583170890808
2025-03-03 07:31:25,934 - Model - INFO - Step 101 Loss: 1.8639878034591675
2025-03-03 07:31:27,491 - Model - INFO - Step 102 Loss: 1.626158595085144
2025-03-03 07:31:28,990 - Model - INFO - Step 103 Loss: 2.085496187210083
2025-03-03 07:31:30,495 - Model - INFO - Step 104 Loss: 2.592564821243286
2025-03-03 07:31:32,032 - Model - INFO - Step 105 Loss: 1.8041893243789673
2025-03-03 07:31:33,541 - Model - INFO - Step 106 Loss: 2.391017436981201
2025-03-03 07:31:35,092 - Model - INFO - Step 107 Loss: 1.9725948572158813
2025-03-03 07:31:36,613 - Model - INFO - Step 108 Loss: 1.7378798723220825
2025-03-03 07:31:38,149 - Model - INFO - Step 109 Loss: 2.3696348667144775
2025-03-03 07:31:39,714 - Model - INFO - Step 110 Loss: 2.575122117996216
2025-03-03 07:31:41,334 - Model - INFO - Step 111 Loss: 1.2771559953689575
2025-03-24 09:06:53,049 - Model - INFO - PARAMETER ...
2025-03-24 09:06:53,049 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:06:53,050 - Model - INFO - Load dataset ...
2025-03-24 09:06:55,515 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:06:55,515 - Model - INFO - Start training...
2025-03-24 09:06:55,516 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:06:57,022 - Model - INFO - Step 0 Loss: 3.901097059249878
2025-03-24 09:07:44,312 - Model - INFO - PARAMETER ...
2025-03-24 09:07:44,312 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:07:44,312 - Model - INFO - Load dataset ...
2025-03-24 09:07:46,703 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:07:46,703 - Model - INFO - Start training...
2025-03-24 09:07:46,703 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:07:48,226 - Model - INFO - Step 0 Loss: 3.8462226390838623
2025-03-24 09:10:42,995 - Model - INFO - PARAMETER ...
2025-03-24 09:10:42,995 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:10:42,995 - Model - INFO - Load dataset ...
2025-03-24 09:10:43,889 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:10:43,889 - Model - INFO - Start training...
2025-03-24 09:10:43,889 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:10:45,346 - Model - INFO - Step 0 Loss: 3.7274694442749023
2025-03-24 09:11:11,035 - Model - INFO - PARAMETER ...
2025-03-24 09:11:11,035 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:11:11,035 - Model - INFO - Load dataset ...
2025-03-24 09:11:11,543 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:11:11,544 - Model - INFO - Start training...
2025-03-24 09:11:11,544 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:11:12,987 - Model - INFO - Step 0 Loss: 3.8292148113250732
2025-03-24 09:12:28,476 - Model - INFO - PARAMETER ...
2025-03-24 09:12:28,476 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:12:28,476 - Model - INFO - Load dataset ...
2025-03-24 09:12:30,385 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:12:30,385 - Model - INFO - Start training...
2025-03-24 09:12:30,385 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:12:31,825 - Model - INFO - Step 0 Loss: 3.9334495067596436
2025-03-24 09:13:36,817 - Model - INFO - PARAMETER ...
2025-03-24 09:13:36,817 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:13:36,817 - Model - INFO - Load dataset ...
2025-03-24 09:13:39,009 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:13:39,009 - Model - INFO - Start training...
2025-03-24 09:13:39,010 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:13:40,481 - Model - INFO - Step 0 Loss: 3.7251203060150146
2025-03-24 09:14:09,974 - Model - INFO - PARAMETER ...
2025-03-24 09:14:09,974 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:14:09,974 - Model - INFO - Load dataset ...
2025-03-24 09:14:10,758 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:14:10,759 - Model - INFO - Start training...
2025-03-24 09:14:10,759 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:14:12,362 - Model - INFO - Step 0 Loss: 3.75215220451355
2025-03-24 09:14:14,492 - Model - INFO - Step 1 Loss: 3.61641526222229
2025-03-24 09:14:16,665 - Model - INFO - Step 2 Loss: 3.593437433242798
2025-03-24 09:14:18,750 - Model - INFO - Step 3 Loss: 3.316317558288574
2025-03-24 09:14:20,920 - Model - INFO - Step 4 Loss: 3.4678242206573486
2025-03-24 09:14:23,043 - Model - INFO - Step 5 Loss: 3.2685177326202393
2025-03-24 09:14:25,254 - Model - INFO - Step 6 Loss: 3.358043670654297
2025-03-24 09:14:27,400 - Model - INFO - Step 7 Loss: 3.166179656982422
2025-03-24 09:14:29,608 - Model - INFO - Step 8 Loss: 3.4600837230682373
2025-03-24 09:14:31,799 - Model - INFO - Step 9 Loss: 3.204562187194824
2025-03-24 09:14:33,975 - Model - INFO - Step 10 Loss: 3.2706470489501953
2025-03-24 09:14:36,155 - Model - INFO - Step 11 Loss: 3.1641042232513428
2025-03-24 09:14:38,319 - Model - INFO - Step 12 Loss: 3.023024320602417
2025-03-24 09:16:13,465 - Model - INFO - PARAMETER ...
2025-03-24 09:16:13,465 - Model - INFO - Namespace(use_cpu=False, gpu='0', batch_size=24, model='pointnet2_cls_ssg', num_category=40, epoch=200, learning_rate=0.001, num_point=1024, optimizer='Adam', log_dir='pointnet2_cls_ssg', decay_rate=0.0001, use_normals=False, process_data=False, use_uniform_sample=False)
2025-03-24 09:16:13,465 - Model - INFO - Load dataset ...
2025-03-24 09:16:15,696 - Model - INFO - No existing model, starting training from scratch...
2025-03-24 09:16:15,697 - Model - INFO - Start training...
2025-03-24 09:16:15,697 - Model - INFO - Epoch 1 (1/200):
2025-03-24 09:16:17,166 - Model - INFO - Step 0 Loss: 3.6661746501922607
2025-03-24 09:16:18,824 - Model - INFO - Step 1 Loss: 3.8536555767059326
2025-03-24 09:16:21,330 - Model - INFO - Step 2 Loss: 3.617056131362915
2025-03-24 09:16:34,516 - Model - INFO - Step 3 Loss: 3.497271776199341
2025-03-24 09:16:36,190 - Model - INFO - Step 4 Loss: 3.495823621749878
2025-03-24 09:16:37,899 - Model - INFO - Step 5 Loss: 3.655730962753296
2025-03-24 09:16:39,774 - Model - INFO - Step 6 Loss: 3.3073253631591797
2025-03-24 09:16:41,480 - Model - INFO - Step 7 Loss: 3.500833749771118
2025-03-24 09:16:43,401 - Model - INFO - Step 8 Loss: 3.5264081954956055
2025-03-24 09:16:45,170 - Model - INFO - Step 9 Loss: 3.2159996032714844
