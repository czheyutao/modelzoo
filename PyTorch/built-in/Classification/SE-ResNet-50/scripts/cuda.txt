/data/softws_up/miniconda3/envs/vae/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0214 17:58:22.642413 140142833640384 torch/distributed/run.py:779] 
W0214 17:58:22.642413 140142833640384 torch/distributed/run.py:779] *****************************************
W0214 17:58:22.642413 140142833640384 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0214 17:58:22.642413 140142833640384 torch/distributed/run.py:779] *****************************************
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Model seresnet50 created, param count: 28088024
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bilinear
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
NVIDIA APEX not installed. AMP off.
Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.
Scheduled epochs: 160
Train: 0 [   0/10009 (  0%)]  Loss:  6.965909 (6.9659)  Time: 13.693s,    9.35/s  (13.693s,    9.35/s)  LR: 1.000e-04  Data: 11.717 (11.717)
Train: 0 [   1/10009 (  0%)]  Loss:  7.056111 (7.0110)  Time: 0.107s, 1194.86/s  (6.900s,   18.55/s)  LR: 1.000e-04  Data: 0.010 (5.864)
Train: 0 [   2/10009 (  0%)]  Loss:  6.971172 (6.9977)  Time: 0.075s, 1711.33/s  (4.625s,   27.68/s)  LR: 1.000e-04  Data: 0.007 (3.911)
Train: 0 [   3/10009 (  0%)]  Loss:  6.986900 (6.9950)  Time: 4.942s,   25.90/s  (4.704s,   27.21/s)  LR: 1.000e-04  Data: 4.858 (4.148)
Train: 0 [   4/10009 (  0%)]  Loss:  6.984413 (6.9929)  Time: 0.187s,  683.92/s  (3.801s,   33.68/s)  LR: 1.000e-04  Data: 0.012 (3.321)
Train: 0 [   5/10009 (  0%)]  Loss:  6.949787 (6.9857)  Time: 0.075s, 1701.40/s  (3.180s,   40.25/s)  LR: 1.000e-04  Data: 0.007 (2.768)
Train: 0 [   6/10009 (  0%)]  Loss:  6.988145 (6.9861)  Time: 0.076s, 1693.83/s  (2.736s,   46.78/s)  LR: 1.000e-04  Data: 0.007 (2.374)
Train: 0 [   7/10009 (  0%)]  Loss:  6.926807 (6.9787)  Time: 5.471s,   23.39/s  (3.078s,   41.58/s)  LR: 1.000e-04  Data: 5.384 (2.750)
Train: 0 [   8/10009 (  0%)]  Loss:  6.970497 (6.9777)  Time: 0.750s,  170.60/s  (2.820s,   45.40/s)  LR: 1.000e-04  Data: 0.023 (2.447)
Train: 0 [   9/10009 (  0%)]  Loss:  6.984774 (6.9785)  Time: 0.081s, 1585.07/s  (2.546s,   50.28/s)  LR: 1.000e-04  Data: 0.008 (2.203)
Train: 0 [  10/10009 (  0%)]  Loss:  6.949652 (6.9758)  Time: 0.076s, 1678.29/s  (2.321s,   55.14/s)  LR: 1.000e-04  Data: 0.005 (2.003)
Train: 0 [  11/10009 (  0%)]  Loss:  7.009030 (6.9786)  Time: 5.051s,   25.34/s  (2.549s,   50.22/s)  LR: 1.000e-04  Data: 4.966 (2.250)
Train: 0 [  12/10009 (  0%)]  Loss:  7.033367 (6.9828)  Time: 2.235s,   57.27/s  (2.525s,   50.70/s)  LR: 1.000e-04  Data: 0.482 (2.114)
Train: 0 [  13/10009 (  0%)]  Loss:  6.962360 (6.9814)  Time: 0.092s, 1398.00/s  (2.351s,   54.45/s)  LR: 1.000e-04  Data: 0.007 (1.964)
Train: 0 [  14/10009 (  0%)]  Loss:  6.980097 (6.9813)  Time: 0.083s, 1535.78/s  (2.200s,   58.19/s)  LR: 1.000e-04  Data: 0.007 (1.833)
Train: 0 [  15/10009 (  0%)]  Loss:  7.011161 (6.9831)  Time: 4.143s,   30.90/s  (2.321s,   55.15/s)  LR: 1.000e-04  Data: 4.058 (1.972)
Train: 0 [  16/10009 (  0%)]  Loss:  6.963131 (6.9820)  Time: 1.662s,   77.01/s  (2.282s,   56.08/s)  LR: 1.000e-04  Data: 1.578 (1.949)
Train: 0 [  17/10009 (  0%)]  Loss:  7.075382 (6.9871)  Time: 0.197s,  649.38/s  (2.166s,   59.08/s)  LR: 1.000e-04  Data: 0.116 (1.847)
Train: 0 [  18/10009 (  0%)]  Loss:  6.932184 (6.9843)  Time: 0.083s, 1537.76/s  (2.057s,   62.23/s)  LR: 1.000e-04  Data: 0.007 (1.750)
Train: 0 [  19/10009 (  0%)]  Loss:  7.005342 (6.9853)  Time: 4.529s,   28.26/s  (2.180s,   58.70/s)  LR: 1.000e-04  Data: 4.444 (1.885)
Train: 0 [  20/10009 (  0%)]  Loss:  6.977944 (6.9850)  Time: 1.624s,   78.82/s  (2.154s,   59.43/s)  LR: 1.000e-04  Data: 1.460 (1.865)
Train: 0 [  21/10009 (  0%)]  Loss:  6.991166 (6.9852)  Time: 0.309s,  413.86/s  (2.070s,   61.83/s)  LR: 1.000e-04  Data: 0.239 (1.791)
Train: 0 [  22/10009 (  0%)]  Loss:  6.930205 (6.9828)  Time: 0.172s,  743.58/s  (1.988s,   64.40/s)  LR: 1.000e-04  Data: 0.101 (1.718)
Train: 0 [  23/10009 (  0%)]  Loss:  6.997313 (6.9835)  Time: 6.052s,   21.15/s  (2.157s,   59.34/s)  LR: 1.000e-04  Data: 5.967 (1.895)
Train: 0 [  24/10009 (  0%)]  Loss:  6.961845 (6.9826)  Time: 2.068s,   61.90/s  (2.153s,   59.44/s)  LR: 1.000e-04  Data: 0.588 (1.842)
Train: 0 [  25/10009 (  0%)]  Loss:  6.978071 (6.9824)  Time: 0.366s,  349.65/s  (2.085s,   61.40/s)  LR: 1.000e-04  Data: 0.297 (1.783)
Train: 0 [  26/10009 (  0%)]  Loss:  6.984560 (6.9825)  Time: 0.077s, 1665.54/s  (2.010s,   63.67/s)  LR: 1.000e-04  Data: 0.008 (1.717)
Train: 0 [  27/10009 (  0%)]  Loss:  7.007638 (6.9834)  Time: 3.792s,   33.75/s  (2.074s,   61.72/s)  LR: 1.000e-04  Data: 3.701 (1.788)
Train: 0 [  28/10009 (  0%)]  Loss:  6.941007 (6.9819)  Time: 0.459s,  279.12/s  (2.018s,   63.42/s)  LR: 1.000e-04  Data: 0.374 (1.739)
Train: 0 [  29/10009 (  0%)]  Loss:  7.007961 (6.9828)  Time: 1.604s,   79.78/s  (2.004s,   63.86/s)  LR: 1.000e-04  Data: 1.521 (1.732)
Train: 0 [  30/10009 (  0%)]  Loss:  6.913541 (6.9806)  Time: 0.499s,  256.54/s  (1.956s,   65.45/s)  LR: 1.000e-04  Data: 0.415 (1.689)
Train: 0 [  31/10009 (  0%)]  Loss:  6.982711 (6.9806)  Time: 5.584s,   22.92/s  (2.069s,   61.86/s)  LR: 1.000e-04  Data: 5.498 (1.808)
Train: 0 [  32/10009 (  0%)]  Loss:  6.959801 (6.9800)  Time: 0.476s,  268.69/s  (2.021s,   63.34/s)  LR: 1.000e-04  Data: 0.007 (1.754)
Train: 0 [  33/10009 (  0%)]  Loss:  6.986712 (6.9802)  Time: 0.081s, 1585.76/s  (1.964s,   65.18/s)  LR: 1.000e-04  Data: 0.008 (1.703)
Train: 0 [  34/10009 (  0%)]  Loss:  6.961377 (6.9797)  Time: 0.079s, 1629.26/s  (1.910s,   67.02/s)  LR: 1.000e-04  Data: 0.007 (1.654)
Train: 0 [  35/10009 (  0%)]  Loss:  6.967508 (6.9793)  Time: 3.424s,   37.39/s  (1.952s,   65.57/s)  LR: 1.000e-04  Data: 3.339 (1.701)
Train: 0 [  36/10009 (  0%)]  Loss:  7.045002 (6.9811)  Time: 1.583s,   80.86/s  (1.942s,   65.91/s)  LR: 1.000e-04  Data: 1.497 (1.695)
Train: 0 [  37/10009 (  0%)]  Loss:  7.008968 (6.9818)  Time: 0.638s,  200.50/s  (1.908s,   67.09/s)  LR: 1.000e-04  Data: 0.005 (1.651)
Train: 0 [  38/10009 (  0%)]  Loss:  7.016059 (6.9827)  Time: 0.313s,  409.28/s  (1.867s,   68.56/s)  LR: 1.000e-04  Data: 0.027 (1.609)
Train: 0 [  39/10009 (  0%)]  Loss:  6.978713 (6.9826)  Time: 3.026s,   42.30/s  (1.896s,   67.52/s)  LR: 1.000e-04  Data: 2.927 (1.642)
Train: 0 [  40/10009 (  0%)]  Loss:  6.981612 (6.9826)  Time: 0.585s,  218.76/s  (1.864s,   68.67/s)  LR: 1.000e-04  Data: 0.503 (1.614)
Train: 0 [  41/10009 (  0%)]  Loss:  6.977410 (6.9825)  Time: 0.080s, 1594.18/s  (1.821s,   70.28/s)  LR: 1.000e-04  Data: 0.006 (1.576)
Train: 0 [  42/10009 (  0%)]  Loss:  6.972186 (6.9822)  Time: 0.095s, 1341.00/s  (1.781s,   71.86/s)  LR: 1.000e-04  Data: 0.008 (1.540)
Train: 0 [  43/10009 (  0%)]  Loss:  7.049564 (6.9838)  Time: 4.552s,   28.12/s  (1.844s,   69.40/s)  LR: 1.000e-04  Data: 4.468 (1.606)
Train: 0 [  44/10009 (  0%)]  Loss:  7.020926 (6.9846)  Time: 0.508s,  252.15/s  (1.815s,   70.54/s)  LR: 1.000e-04  Data: 0.422 (1.580)
Train: 0 [  45/10009 (  0%)]  Loss:  7.013355 (6.9852)  Time: 0.202s,  634.05/s  (1.779s,   71.93/s)  LR: 1.000e-04  Data: 0.008 (1.546)
Train: 0 [  46/10009 (  0%)]  Loss:  7.033224 (6.9862)  Time: 0.413s,  310.16/s  (1.750s,   73.13/s)  LR: 1.000e-04  Data: 0.009 (1.513)
Train: 0 [  47/10009 (  0%)]  Loss:  7.028404 (6.9871)  Time: 3.351s,   38.20/s  (1.784s,   71.76/s)  LR: 1.000e-04  Data: 3.014 (1.544)
Train: 0 [  48/10009 (  0%)]  Loss:  6.997268 (6.9873)  Time: 0.089s, 1433.29/s  (1.749s,   73.18/s)  LR: 1.000e-04  Data: 0.008 (1.513)
Train: 0 [  49/10009 (  0%)]  Loss:  7.003038 (6.9876)  Time: 1.291s,   99.14/s  (1.740s,   73.56/s)  LR: 1.000e-04  Data: 0.007 (1.483)
Train: 0 [  50/10009 (  0%)]  Loss:  7.039375 (6.9886)  Time: 0.291s,  439.73/s  (1.712s,   74.78/s)  LR: 1.000e-04  Data: 0.008 (1.454)
Train: 0 [  51/10009 (  1%)]  Loss:  7.055886 (6.9899)  Time: 3.352s,   38.18/s  (1.743s,   73.43/s)  LR: 1.000e-04  Data: 3.167 (1.487)
Train: 0 [  52/10009 (  1%)]  Loss:  6.963289 (6.9894)  Time: 0.258s,  496.57/s  (1.715s,   74.63/s)  LR: 1.000e-04  Data: 0.007 (1.459)
Train: 0 [  53/10009 (  1%)]  Loss:  6.977034 (6.9892)  Time: 0.303s,  421.86/s  (1.689s,   75.79/s)  LR: 1.000e-04  Data: 0.066 (1.433)
Train: 0 [  54/10009 (  1%)]  Loss:  6.946898 (6.9884)  Time: 0.078s, 1642.93/s  (1.660s,   77.12/s)  LR: 1.000e-04  Data: 0.006 (1.407)
Train: 0 [  55/10009 (  1%)]  Loss:  6.991478 (6.9885)  Time: 3.356s,   38.14/s  (1.690s,   75.74/s)  LR: 1.000e-04  Data: 3.204 (1.439)
Train: 0 [  56/10009 (  1%)]  Loss:  6.943930 (6.9877)  Time: 1.733s,   73.87/s  (1.691s,   75.71/s)  LR: 1.000e-04  Data: 0.009 (1.414)
Train: 0 [  57/10009 (  1%)]  Loss:  6.945611 (6.9870)  Time: 0.399s,  321.00/s  (1.668s,   76.72/s)  LR: 1.000e-04  Data: 0.006 (1.390)
Train: 0 [  58/10009 (  1%)]  Loss:  6.935158 (6.9861)  Time: 0.077s, 1670.33/s  (1.641s,   77.98/s)  LR: 1.000e-04  Data: 0.008 (1.367)
Train: 0 [  59/10009 (  1%)]  Loss:  6.956871 (6.9856)  Time: 3.426s,   37.36/s  (1.671s,   76.59/s)  LR: 1.000e-04  Data: 2.986 (1.394)
Train: 0 [  60/10009 (  1%)]  Loss:  6.981966 (6.9856)  Time: 0.340s,  376.16/s  (1.649s,   77.60/s)  LR: 1.000e-04  Data: 0.011 (1.371)
Train: 0 [  61/10009 (  1%)]  Loss:  6.899764 (6.9842)  Time: 1.366s,   93.73/s  (1.645s,   77.82/s)  LR: 1.000e-04  Data: 0.006 (1.349)
Train: 0 [  62/10009 (  1%)]  Loss:  7.002791 (6.9845)  Time: 0.082s, 1554.48/s  (1.620s,   79.01/s)  LR: 1.000e-04  Data: 0.008 (1.328)
Train: 0 [  63/10009 (  1%)]  Loss:  7.000403 (6.9847)  Time: 3.575s,   35.81/s  (1.651s,   77.55/s)  LR: 1.000e-04  Data: 3.304 (1.358)
Train: 0 [  64/10009 (  1%)]  Loss:  7.007797 (6.9851)  Time: 0.343s,  373.23/s  (1.630s,   78.51/s)  LR: 1.000e-04  Data: 0.006 (1.338)
Train: 0 [  65/10009 (  1%)]  Loss:  6.935704 (6.9843)  Time: 0.177s,  723.22/s  (1.608s,   79.58/s)  LR: 1.000e-04  Data: 0.006 (1.317)
Train: 0 [  66/10009 (  1%)]  Loss:  6.963164 (6.9840)  Time: 0.080s, 1590.43/s  (1.586s,   80.73/s)  LR: 1.000e-04  Data: 0.008 (1.298)
Train: 0 [  67/10009 (  1%)]  Loss:  6.987031 (6.9841)  Time: 5.229s,   24.48/s  (1.639s,   78.09/s)  LR: 1.000e-04  Data: 3.149 (1.325)
Train: 0 [  68/10009 (  1%)]  Loss:  6.969188 (6.9838)  Time: 0.397s,  322.09/s  (1.621s,   78.95/s)  LR: 1.000e-04  Data: 0.007 (1.306)
Train: 0 [  69/10009 (  1%)]  Loss:  6.978107 (6.9838)  Time: 0.290s,  441.52/s  (1.602s,   79.89/s)  LR: 1.000e-04  Data: 0.006 (1.287)
Train: 0 [  70/10009 (  1%)]  Loss:  6.960594 (6.9834)  Time: 0.076s, 1685.18/s  (1.581s,   80.98/s)  LR: 1.000e-04  Data: 0.007 (1.269)
Train: 0 [  71/10009 (  1%)]  Loss:  7.054131 (6.9844)  Time: 3.210s,   39.88/s  (1.603s,   79.83/s)  LR: 1.000e-04  Data: 2.923 (1.292)
Train: 0 [  72/10009 (  1%)]  Loss:  6.950717 (6.9839)  Time: 1.999s,   64.05/s  (1.609s,   79.57/s)  LR: 1.000e-04  Data: 0.006 (1.275)
Train: 0 [  73/10009 (  1%)]  Loss:  6.978691 (6.9839)  Time: 0.263s,  487.02/s  (1.591s,   80.48/s)  LR: 1.000e-04  Data: 0.007 (1.258)
Train: 0 [  74/10009 (  1%)]  Loss:  6.994034 (6.9840)  Time: 0.075s, 1717.21/s  (1.570s,   81.51/s)  LR: 1.000e-04  Data: 0.007 (1.241)
Train: 0 [  75/10009 (  1%)]  Loss:  6.930095 (6.9833)  Time: 0.725s,  176.57/s  (1.559s,   82.09/s)  LR: 1.000e-04  Data: 0.411 (1.230)
Train: 0 [  76/10009 (  1%)]  Loss:  7.003350 (6.9836)  Time: 0.081s, 1589.52/s  (1.540s,   83.12/s)  LR: 1.000e-04  Data: 0.007 (1.214)
Train: 0 [  77/10009 (  1%)]  Loss:  6.985476 (6.9836)  Time: 1.332s,   96.07/s  (1.537s,   83.26/s)  LR: 1.000e-04  Data: 0.007 (1.199)
Train: 0 [  78/10009 (  1%)]  Loss:  6.966534 (6.9834)  Time: 0.076s, 1688.57/s  (1.519s,   84.27/s)  LR: 1.000e-04  Data: 0.007 (1.184)
Train: 0 [  79/10009 (  1%)]  Loss:  6.927854 (6.9827)  Time: 0.788s,  162.35/s  (1.510s,   84.78/s)  LR: 1.000e-04  Data: 0.466 (1.175)
Train: 0 [  80/10009 (  1%)]  Loss:  7.008307 (6.9830)  Time: 0.110s, 1167.05/s  (1.492s,   85.77/s)  LR: 1.000e-04  Data: 0.006 (1.160)
Train: 0 [  81/10009 (  1%)]  Loss:  6.948600 (6.9826)  Time: 0.307s,  416.49/s  (1.478s,   86.60/s)  LR: 1.000e-04  Data: 0.009 (1.146)
Train: 0 [  82/10009 (  1%)]  Loss:  6.976731 (6.9825)  Time: 0.074s, 1735.60/s  (1.461s,   87.61/s)  LR: 1.000e-04  Data: 0.006 (1.132)
Train: 0 [  83/10009 (  1%)]  Loss:  6.975063 (6.9824)  Time: 0.480s,  266.89/s  (1.449s,   88.31/s)  LR: 1.000e-04  Data: 0.007 (1.119)
Train: 0 [  84/10009 (  1%)]  Loss:  6.984554 (6.9824)  Time: 1.331s,   96.20/s  (1.448s,   88.40/s)  LR: 1.000e-04  Data: 0.007 (1.106)
Train: 0 [  85/10009 (  1%)]  Loss:  7.009727 (6.9828)  Time: 0.550s,  232.87/s  (1.438s,   89.04/s)  LR: 1.000e-04  Data: 0.128 (1.095)
Train: 0 [  86/10009 (  1%)]  Loss:  6.960256 (6.9825)  Time: 0.081s, 1571.09/s  (1.422s,   90.02/s)  LR: 1.000e-04  Data: 0.005 (1.082)
Train: 0 [  87/10009 (  1%)]  Loss:  7.033041 (6.9831)  Time: 0.140s,  912.26/s  (1.407s,   90.95/s)  LR: 1.000e-04  Data: 0.006 (1.070)
Train: 0 [  88/10009 (  1%)]  Loss:  7.014200 (6.9834)  Time: 0.146s,  876.49/s  (1.393s,   91.87/s)  LR: 1.000e-04  Data: 0.006 (1.058)
Train: 0 [  89/10009 (  1%)]  Loss:  6.991100 (6.9835)  Time: 0.460s,  278.54/s  (1.383s,   92.56/s)  LR: 1.000e-04  Data: 0.008 (1.046)
Train: 0 [  90/10009 (  1%)]  Loss:  6.967993 (6.9833)  Time: 0.084s, 1525.73/s  (1.369s,   93.53/s)  LR: 1.000e-04  Data: 0.009 (1.035)
Train: 0 [  91/10009 (  1%)]  Loss:  7.018240 (6.9837)  Time: 0.189s,  675.50/s  (1.356s,   94.41/s)  LR: 1.000e-04  Data: 0.008 (1.024)
Train: 0 [  92/10009 (  1%)]  Loss:  6.978215 (6.9837)  Time: 1.121s,  114.19/s  (1.353s,   94.59/s)  LR: 1.000e-04  Data: 0.006 (1.013)
Train: 0 [  93/10009 (  1%)]  Loss:  7.015698 (6.9840)  Time: 0.463s,  276.39/s  (1.344s,   95.26/s)  LR: 1.000e-04  Data: 0.008 (1.002)
Train: 0 [  94/10009 (  1%)]  Loss:  6.985839 (6.9840)  Time: 0.083s, 1539.21/s  (1.330s,   96.21/s)  LR: 1.000e-04  Data: 0.006 (0.992)
Train: 0 [  95/10009 (  1%)]  Loss:  7.017487 (6.9844)  Time: 0.181s,  708.56/s  (1.319s,   97.08/s)  LR: 1.000e-04  Data: 0.008 (0.981)
Train: 0 [  96/10009 (  1%)]  Loss:  7.016696 (6.9847)  Time: 0.176s,  728.70/s  (1.307s,   97.95/s)  LR: 1.000e-04  Data: 0.006 (0.971)
Train: 0 [  97/10009 (  1%)]  Loss:  6.991769 (6.9848)  Time: 0.279s,  459.25/s  (1.296s,   98.75/s)  LR: 1.000e-04  Data: 0.006 (0.961)
Train: 0 [  98/10009 (  1%)]  Loss:  6.992902 (6.9849)  Time: 0.076s, 1679.51/s  (1.284s,   99.70/s)  LR: 1.000e-04  Data: 0.007 (0.952)
Train: 0 [  99/10009 (  1%)]  Loss:  6.941541 (6.9844)  Time: 0.466s,  274.93/s  (1.276s,  100.33/s)  LR: 1.000e-04  Data: 0.008 (0.942)
