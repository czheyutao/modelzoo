/data/softws_up/miniconda3/envs/vae/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0214 16:18:11.618086 139882233717696 torch/distributed/run.py:779] 
W0214 16:18:11.618086 139882233717696 torch/distributed/run.py:779] *****************************************
W0214 16:18:11.618086 139882233717696 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0214 16:18:11.618086 139882233717696 torch/distributed/run.py:779] *****************************************
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Model seresnet34 created, param count: 21958868
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bilinear
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
NVIDIA APEX not installed. AMP off.
Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.
Scheduled epochs: 160
Train: 0 [   0/1251 (  0%)]  Loss:  7.064015 (7.0640)  Time: 13.019s,   78.65/s  (13.019s,   78.65/s)  LR: 1.000e-04  Data: 9.361 (9.361)
Train: 0 [   1/1251 (  0%)]  Loss:  7.053663 (7.0588)  Time: 0.336s, 3046.72/s  (6.678s,  153.35/s)  LR: 1.000e-04  Data: 0.134 (4.748)
Train: 0 [   2/1251 (  0%)]  Loss:  7.064418 (7.0607)  Time: 0.242s, 4237.38/s  (4.532s,  225.93/s)  LR: 1.000e-04  Data: 0.049 (3.181)
Train: 0 [   3/1251 (  0%)]  Loss:  7.143202 (7.0813)  Time: 2.345s,  436.60/s  (3.986s,  256.93/s)  LR: 1.000e-04  Data: 2.114 (2.915)
Train: 0 [   4/1251 (  0%)]  Loss:  7.055170 (7.0761)  Time: 0.252s, 4063.59/s  (3.239s,  316.16/s)  LR: 1.000e-04  Data: 0.045 (2.341)
Train: 0 [   5/1251 (  0%)]  Loss:  7.055145 (7.0726)  Time: 1.057s,  968.86/s  (2.875s,  356.15/s)  LR: 1.000e-04  Data: 0.048 (1.959)
Train: 0 [   6/1251 (  0%)]  Loss:  7.106736 (7.0775)  Time: 0.636s, 1609.35/s  (2.555s,  400.73/s)  LR: 1.000e-04  Data: 0.442 (1.742)
Train: 0 [   7/1251 (  1%)]  Loss:  7.073118 (7.0769)  Time: 4.443s,  230.47/s  (2.791s,  366.85/s)  LR: 1.000e-04  Data: 4.198 (2.049)
Train: 0 [   8/1251 (  1%)]  Loss:  7.060016 (7.0751)  Time: 0.735s, 1393.42/s  (2.563s,  399.56/s)  LR: 1.000e-04  Data: 0.042 (1.826)
Train: 0 [   9/1251 (  1%)]  Loss:  7.086943 (7.0762)  Time: 0.983s, 1042.11/s  (2.405s,  425.81/s)  LR: 1.000e-04  Data: 0.041 (1.647)
Train: 0 [  10/1251 (  1%)]  Loss:  7.071637 (7.0758)  Time: 0.241s, 4253.27/s  (2.208s,  463.75/s)  LR: 1.000e-04  Data: 0.048 (1.502)
Train: 0 [  11/1251 (  1%)]  Loss:  7.059017 (7.0744)  Time: 5.276s,  194.08/s  (2.464s,  415.63/s)  LR: 1.000e-04  Data: 5.025 (1.796)
Train: 0 [  12/1251 (  1%)]  Loss:  7.063713 (7.0736)  Time: 0.981s, 1043.66/s  (2.350s,  435.80/s)  LR: 1.000e-04  Data: 0.054 (1.662)
Train: 0 [  13/1251 (  1%)]  Loss:  7.055367 (7.0723)  Time: 0.246s, 4162.79/s  (2.199s,  465.57/s)  LR: 1.000e-04  Data: 0.050 (1.546)
Train: 0 [  14/1251 (  1%)]  Loss:  7.088462 (7.0734)  Time: 0.245s, 4181.40/s  (2.069s,  494.89/s)  LR: 1.000e-04  Data: 0.044 (1.446)
Train: 0 [  15/1251 (  1%)]  Loss:  7.042405 (7.0714)  Time: 8.838s,  115.86/s  (2.492s,  410.88/s)  LR: 1.000e-04  Data: 8.601 (1.894)
Train: 0 [  16/1251 (  1%)]  Loss:  7.087200 (7.0724)  Time: 0.247s, 4152.13/s  (2.360s,  433.88/s)  LR: 1.000e-04  Data: 0.042 (1.785)
Train: 0 [  17/1251 (  1%)]  Loss:  7.069664 (7.0722)  Time: 0.245s, 4172.61/s  (2.243s,  456.61/s)  LR: 1.000e-04  Data: 0.053 (1.688)
Train: 0 [  18/1251 (  1%)]  Loss:  7.084686 (7.0729)  Time: 0.245s, 4184.27/s  (2.137s,  479.07/s)  LR: 1.000e-04  Data: 0.047 (1.602)
Train: 0 [  19/1251 (  2%)]  Loss:  7.083623 (7.0734)  Time: 11.796s,   86.81/s  (2.620s,  390.78/s)  LR: 1.000e-04  Data: 11.565 (2.100)
Train: 0 [  20/1251 (  2%)]  Loss:  7.058815 (7.0727)  Time: 0.250s, 4089.79/s  (2.508s,  408.36/s)  LR: 1.000e-04  Data: 0.054 (2.003)
Train: 0 [  21/1251 (  2%)]  Loss:  7.076842 (7.0729)  Time: 0.239s, 4290.21/s  (2.404s,  425.88/s)  LR: 1.000e-04  Data: 0.044 (1.914)
Train: 0 [  22/1251 (  2%)]  Loss:  7.067798 (7.0727)  Time: 0.240s, 4273.86/s  (2.310s,  443.23/s)  LR: 1.000e-04  Data: 0.046 (1.832)
Train: 0 [  23/1251 (  2%)]  Loss:  7.055368 (7.0720)  Time: 13.622s,   75.17/s  (2.782s,  368.13/s)  LR: 1.000e-04  Data: 13.362 (2.313)
Train: 0 [  24/1251 (  2%)]  Loss:  7.051776 (7.0712)  Time: 0.244s, 4193.67/s  (2.680s,  382.07/s)  LR: 1.000e-04  Data: 0.047 (2.222)
Train: 0 [  25/1251 (  2%)]  Loss:  7.061175 (7.0708)  Time: 0.243s, 4219.21/s  (2.586s,  395.92/s)  LR: 1.000e-04  Data: 0.048 (2.139)
Train: 0 [  26/1251 (  2%)]  Loss:  7.088773 (7.0714)  Time: 0.237s, 4314.20/s  (2.499s,  409.70/s)  LR: 1.000e-04  Data: 0.044 (2.061)
Train: 0 [  27/1251 (  2%)]  Loss:  7.059513 (7.0710)  Time: 10.713s,   95.58/s  (2.793s,  366.67/s)  LR: 1.000e-04  Data: 9.723 (2.335)
Train: 0 [  28/1251 (  2%)]  Loss:  7.064937 (7.0708)  Time: 0.244s, 4201.80/s  (2.705s,  378.58/s)  LR: 1.000e-04  Data: 0.047 (2.256)
Train: 0 [  29/1251 (  2%)]  Loss:  7.087479 (7.0714)  Time: 0.244s, 4190.48/s  (2.623s,  390.42/s)  LR: 1.000e-04  Data: 0.045 (2.182)
Train: 0 [  30/1251 (  2%)]  Loss:  7.069345 (7.0713)  Time: 0.239s, 4284.03/s  (2.546s,  402.21/s)  LR: 1.000e-04  Data: 0.046 (2.113)
Train: 0 [  31/1251 (  2%)]  Loss:  7.048018 (7.0706)  Time: 13.207s,   77.53/s  (2.879s,  355.67/s)  LR: 1.000e-04  Data: 11.785 (2.415)
Train: 0 [  32/1251 (  3%)]  Loss:  7.057204 (7.0702)  Time: 1.024s, 1000.00/s  (2.823s,  362.75/s)  LR: 1.000e-04  Data: 0.042 (2.344)
Train: 0 [  33/1251 (  3%)]  Loss:  7.046205 (7.0695)  Time: 0.666s, 1538.24/s  (2.759s,  371.09/s)  LR: 1.000e-04  Data: 0.041 (2.276)
Train: 0 [  34/1251 (  3%)]  Loss:  7.059185 (7.0692)  Time: 0.240s, 4261.26/s  (2.687s,  381.03/s)  LR: 1.000e-04  Data: 0.044 (2.212)
Train: 0 [  35/1251 (  3%)]  Loss:  7.063695 (7.0690)  Time: 13.207s,   77.53/s  (2.980s,  343.66/s)  LR: 1.000e-04  Data: 9.834 (2.424)
Train: 0 [  36/1251 (  3%)]  Loss:  7.067546 (7.0690)  Time: 1.408s,  727.07/s  (2.937s,  348.63/s)  LR: 1.000e-04  Data: 0.047 (2.360)
Train: 0 [  37/1251 (  3%)]  Loss:  7.055518 (7.0686)  Time: 0.246s, 4155.24/s  (2.866s,  357.24/s)  LR: 1.000e-04  Data: 0.046 (2.299)
Train: 0 [  38/1251 (  3%)]  Loss:  7.051754 (7.0682)  Time: 0.243s, 4221.34/s  (2.799s,  365.83/s)  LR: 1.000e-04  Data: 0.047 (2.241)
Train: 0 [  39/1251 (  3%)]  Loss:  7.056030 (7.0679)  Time: 12.806s,   79.96/s  (3.049s,  335.81/s)  LR: 1.000e-04  Data: 6.014 (2.335)
Train: 0 [  40/1251 (  3%)]  Loss:  7.081982 (7.0682)  Time: 0.250s, 4100.59/s  (2.981s,  343.51/s)  LR: 1.000e-04  Data: 0.050 (2.280)
Train: 0 [  41/1251 (  3%)]  Loss:  7.049470 (7.0678)  Time: 0.245s, 4178.14/s  (2.916s,  351.18/s)  LR: 1.000e-04  Data: 0.045 (2.226)
Train: 0 [  42/1251 (  3%)]  Loss:  7.052523 (7.0674)  Time: 0.243s, 4219.68/s  (2.854s,  358.83/s)  LR: 1.000e-04  Data: 0.050 (2.176)
Train: 0 [  43/1251 (  3%)]  Loss:  7.051135 (7.0671)  Time: 13.838s,   74.00/s  (3.103s,  329.97/s)  LR: 1.000e-04  Data: 7.023 (2.286)
Train: 0 [  44/1251 (  4%)]  Loss:  7.063125 (7.0670)  Time: 0.242s, 4226.50/s  (3.040s,  336.87/s)  LR: 1.000e-04  Data: 0.046 (2.236)
Train: 0 [  45/1251 (  4%)]  Loss:  7.081178 (7.0673)  Time: 0.243s, 4206.29/s  (2.979s,  343.74/s)  LR: 1.000e-04  Data: 0.049 (2.189)
Train: 0 [  46/1251 (  4%)]  Loss:  7.056760 (7.0670)  Time: 0.240s, 4263.42/s  (2.921s,  350.60/s)  LR: 1.000e-04  Data: 0.047 (2.143)
Train: 0 [  47/1251 (  4%)]  Loss:  7.036480 (7.0664)  Time: 18.197s,   56.27/s  (3.239s,  316.15/s)  LR: 1.000e-04  Data: 10.035 (2.307)
Train: 0 [  48/1251 (  4%)]  Loss:  7.102536 (7.0672)  Time: 0.245s, 4178.53/s  (3.178s,  322.23/s)  LR: 1.000e-04  Data: 0.050 (2.261)
Train: 0 [  49/1251 (  4%)]  Loss:  7.046796 (7.0667)  Time: 0.240s, 4275.21/s  (3.119s,  328.30/s)  LR: 1.000e-04  Data: 0.047 (2.217)
Train: 0 [  50/1251 (  4%)]  Loss:  7.058070 (7.0666)  Time: 0.243s, 4209.04/s  (3.063s,  334.34/s)  LR: 1.000e-04  Data: 0.047 (2.175)
Train: 0 [  51/1251 (  4%)]  Loss:  7.072414 (7.0667)  Time: 17.906s,   57.19/s  (3.348s,  305.84/s)  LR: 1.000e-04  Data: 8.046 (2.287)
Train: 0 [  52/1251 (  4%)]  Loss:  7.062140 (7.0666)  Time: 0.241s, 4249.53/s  (3.290s,  311.29/s)  LR: 1.000e-04  Data: 0.047 (2.245)
Train: 0 [  53/1251 (  4%)]  Loss:  7.078318 (7.0668)  Time: 0.243s, 4220.82/s  (3.233s,  316.72/s)  LR: 1.000e-04  Data: 0.048 (2.204)
Train: 0 [  54/1251 (  4%)]  Loss:  7.045309 (7.0664)  Time: 0.244s, 4188.21/s  (3.179s,  322.14/s)  LR: 1.000e-04  Data: 0.048 (2.165)
Train: 0 [  55/1251 (  4%)]  Loss:  7.084749 (7.0668)  Time: 17.996s,   56.90/s  (3.443s,  297.38/s)  LR: 1.000e-04  Data: 4.975 (2.215)
Train: 0 [  56/1251 (  4%)]  Loss:  7.033311 (7.0662)  Time: 0.239s, 4284.75/s  (3.387s,  302.32/s)  LR: 1.000e-04  Data: 0.047 (2.177)
Train: 0 [  57/1251 (  5%)]  Loss:  7.045780 (7.0658)  Time: 0.242s, 4232.05/s  (3.333s,  307.24/s)  LR: 1.000e-04  Data: 0.046 (2.141)
Train: 0 [  58/1251 (  5%)]  Loss:  7.042396 (7.0654)  Time: 0.242s, 4234.63/s  (3.281s,  312.14/s)  LR: 1.000e-04  Data: 0.049 (2.105)
Train: 0 [  59/1251 (  5%)]  Loss:  7.055053 (7.0652)  Time: 17.129s,   59.78/s  (3.511s,  291.63/s)  LR: 1.000e-04  Data: 2.398 (2.110)
Train: 0 [  60/1251 (  5%)]  Loss:  7.068106 (7.0653)  Time: 0.628s, 1630.73/s  (3.464s,  295.61/s)  LR: 1.000e-04  Data: 0.214 (2.079)
Train: 0 [  61/1251 (  5%)]  Loss:  7.047070 (7.0650)  Time: 0.637s, 1607.79/s  (3.418s,  299.55/s)  LR: 1.000e-04  Data: 0.233 (2.049)
Train: 0 [  62/1251 (  5%)]  Loss:  7.043790 (7.0647)  Time: 0.551s, 1857.81/s  (3.373s,  303.59/s)  LR: 1.000e-04  Data: 0.128 (2.019)
Train: 0 [  63/1251 (  5%)]  Loss:  7.085705 (7.0650)  Time: 16.629s,   61.58/s  (3.580s,  286.03/s)  LR: 1.000e-04  Data: 1.923 (2.017)
Train: 0 [  64/1251 (  5%)]  Loss:  7.081235 (7.0652)  Time: 0.542s, 1889.05/s  (3.533s,  289.81/s)  LR: 1.000e-04  Data: 0.155 (1.989)
Train: 0 [  65/1251 (  5%)]  Loss:  7.059289 (7.0651)  Time: 0.572s, 1791.32/s  (3.488s,  293.54/s)  LR: 1.000e-04  Data: 0.177 (1.961)
Train: 0 [  66/1251 (  5%)]  Loss:  7.066988 (7.0652)  Time: 0.548s, 1869.35/s  (3.445s,  297.28/s)  LR: 1.000e-04  Data: 0.163 (1.934)
Train: 0 [  67/1251 (  5%)]  Loss:  7.058304 (7.0651)  Time: 14.621s,   70.04/s  (3.609s,  283.74/s)  LR: 1.000e-04  Data: 0.154 (1.908)
Train: 0 [  68/1251 (  5%)]  Loss:  7.075809 (7.0652)  Time: 0.244s, 4204.03/s  (3.560s,  287.63/s)  LR: 1.000e-04  Data: 0.052 (1.881)
Train: 0 [  69/1251 (  6%)]  Loss:  7.044973 (7.0649)  Time: 0.240s, 4261.81/s  (3.513s,  291.51/s)  LR: 1.000e-04  Data: 0.042 (1.855)
Train: 0 [  70/1251 (  6%)]  Loss:  7.053969 (7.0648)  Time: 0.243s, 4217.95/s  (3.467s,  295.38/s)  LR: 1.000e-04  Data: 0.046 (1.829)
Train: 0 [  71/1251 (  6%)]  Loss:  7.077393 (7.0650)  Time: 17.706s,   57.83/s  (3.664s,  279.44/s)  LR: 1.000e-04  Data: 0.048 (1.805)
Train: 0 [  72/1251 (  6%)]  Loss:  7.063272 (7.0649)  Time: 0.242s, 4235.65/s  (3.618s,  283.06/s)  LR: 1.000e-04  Data: 0.050 (1.781)
Train: 0 [  73/1251 (  6%)]  Loss:  7.045949 (7.0647)  Time: 0.242s, 4223.55/s  (3.572s,  286.68/s)  LR: 1.000e-04  Data: 0.043 (1.757)
Train: 0 [  74/1251 (  6%)]  Loss:  7.072420 (7.0648)  Time: 0.239s, 4288.40/s  (3.527s,  290.29/s)  LR: 1.000e-04  Data: 0.046 (1.734)
Train: 0 [  75/1251 (  6%)]  Loss:  7.056726 (7.0647)  Time: 15.046s,   68.06/s  (3.679s,  278.33/s)  LR: 1.000e-04  Data: 0.045 (1.712)
Train: 0 [  76/1251 (  6%)]  Loss:  7.078406 (7.0649)  Time: 0.248s, 4133.18/s  (3.634s,  281.75/s)  LR: 1.000e-04  Data: 0.049 (1.690)
Train: 0 [  77/1251 (  6%)]  Loss:  7.069016 (7.0649)  Time: 0.247s, 4141.14/s  (3.591s,  285.15/s)  LR: 1.000e-04  Data: 0.045 (1.669)
Train: 0 [  78/1251 (  6%)]  Loss:  7.093400 (7.0653)  Time: 0.243s, 4219.42/s  (3.549s,  288.56/s)  LR: 1.000e-04  Data: 0.046 (1.649)
Train: 0 [  79/1251 (  6%)]  Loss:  7.047337 (7.0650)  Time: 20.434s,   50.11/s  (3.760s,  272.36/s)  LR: 1.000e-04  Data: 0.042 (1.629)
Train: 0 [  80/1251 (  6%)]  Loss:  7.059009 (7.0650)  Time: 0.245s, 4183.00/s  (3.716s,  275.54/s)  LR: 1.000e-04  Data: 0.049 (1.609)
Train: 0 [  81/1251 (  6%)]  Loss:  7.043560 (7.0647)  Time: 0.249s, 4115.79/s  (3.674s,  278.71/s)  LR: 1.000e-04  Data: 0.048 (1.590)
Train: 0 [  82/1251 (  7%)]  Loss:  7.083056 (7.0649)  Time: 0.239s, 4282.31/s  (3.633s,  281.89/s)  LR: 1.000e-04  Data: 0.046 (1.572)
Train: 0 [  83/1251 (  7%)]  Loss:  7.075169 (7.0651)  Time: 17.527s,   58.42/s  (3.798s,  269.61/s)  LR: 1.000e-04  Data: 0.047 (1.553)
Train: 0 [  84/1251 (  7%)]  Loss:  7.061465 (7.0650)  Time: 0.241s, 4244.70/s  (3.756s,  272.61/s)  LR: 1.000e-04  Data: 0.050 (1.536)
Train: 0 [  85/1251 (  7%)]  Loss:  7.039598 (7.0647)  Time: 0.239s, 4279.07/s  (3.715s,  275.61/s)  LR: 1.000e-04  Data: 0.048 (1.518)
Train: 0 [  86/1251 (  7%)]  Loss:  7.064642 (7.0647)  Time: 0.238s, 4308.03/s  (3.675s,  278.61/s)  LR: 1.000e-04  Data: 0.046 (1.502)
Train: 0 [  87/1251 (  7%)]  Loss:  7.050617 (7.0646)  Time: 19.294s,   53.07/s  (3.853s,  265.78/s)  LR: 1.000e-04  Data: 0.044 (1.485)
Train: 0 [  88/1251 (  7%)]  Loss:  7.043650 (7.0643)  Time: 0.241s, 4242.71/s  (3.812s,  268.61/s)  LR: 1.000e-04  Data: 0.050 (1.469)
Train: 0 [  89/1251 (  7%)]  Loss:  7.060771 (7.0643)  Time: 0.241s, 4240.99/s  (3.773s,  271.43/s)  LR: 1.000e-04  Data: 0.044 (1.453)
Train: 0 [  90/1251 (  7%)]  Loss:  7.073667 (7.0644)  Time: 0.240s, 4263.79/s  (3.734s,  274.25/s)  LR: 1.000e-04  Data: 0.049 (1.438)
Train: 0 [  91/1251 (  7%)]  Loss:  7.052004 (7.0643)  Time: 16.560s,   61.83/s  (3.873s,  264.38/s)  LR: 1.000e-04  Data: 0.046 (1.422)
Train: 0 [  92/1251 (  7%)]  Loss:  7.044080 (7.0640)  Time: 0.242s, 4234.10/s  (3.834s,  267.07/s)  LR: 1.000e-04  Data: 0.051 (1.408)
Train: 0 [  93/1251 (  7%)]  Loss:  7.060472 (7.0640)  Time: 0.239s, 4293.22/s  (3.796s,  269.76/s)  LR: 1.000e-04  Data: 0.046 (1.393)
Train: 0 [  94/1251 (  8%)]  Loss:  7.071630 (7.0641)  Time: 0.240s, 4260.38/s  (3.758s,  272.45/s)  LR: 1.000e-04  Data: 0.048 (1.379)
Train: 0 [  95/1251 (  8%)]  Loss:  7.064928 (7.0641)  Time: 17.339s,   59.06/s  (3.900s,  262.57/s)  LR: 1.000e-04  Data: 1.272 (1.378)
Train: 0 [  96/1251 (  8%)]  Loss:  7.054318 (7.0640)  Time: 0.249s, 4112.64/s  (3.862s,  265.13/s)  LR: 1.000e-04  Data: 0.057 (1.364)
Train: 0 [  97/1251 (  8%)]  Loss:  7.049364 (7.0638)  Time: 0.248s, 4129.30/s  (3.825s,  267.68/s)  LR: 1.000e-04  Data: 0.055 (1.351)
Train: 0 [  98/1251 (  8%)]  Loss:  7.045875 (7.0637)  Time: 1.016s, 1008.23/s  (3.797s,  269.68/s)  LR: 1.000e-04  Data: 0.048 (1.338)
Train: 0 [  99/1251 (  8%)]  Loss:  7.054210 (7.0636)  Time: 7.522s,  136.14/s  (3.834s,  267.06/s)  LR: 1.000e-04  Data: 0.046 (1.325)
