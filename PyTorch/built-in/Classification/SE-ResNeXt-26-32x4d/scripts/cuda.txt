/data/softws_up/miniconda3/envs/vae/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0217 18:40:46.162539 139733117637568 torch/distributed/run.py:779] 
W0217 18:40:46.162539 139733117637568 torch/distributed/run.py:779] *****************************************
W0217 18:40:46.162539 139733117637568 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0217 18:40:46.162539 139733117637568 torch/distributed/run.py:779] *****************************************
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Model seresnext26_32x4d created, param count: 16790280
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
NVIDIA APEX not installed. AMP off.
Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.
Scheduled epochs: 160
Train: 0 [   0/2502 (  0%)]  Loss:  6.990857 (6.9909)  Time: 20.505s,   24.97/s  (20.505s,   24.97/s)  LR: 1.000e-04  Data: 16.919 (16.919)
Train: 0 [   1/2502 (  0%)]  Loss:  6.974307 (6.9826)  Time: 0.218s, 2345.95/s  (10.362s,   49.41/s)  LR: 1.000e-04  Data: 0.050 (8.485)
Train: 0 [   2/2502 (  0%)]  Loss:  6.961238 (6.9755)  Time: 0.168s, 3052.61/s  (6.964s,   73.52/s)  LR: 1.000e-04  Data: 0.023 (5.664)
Train: 0 [   3/2502 (  0%)]  Loss:  6.978887 (6.9763)  Time: 1.529s,  334.78/s  (5.605s,   91.35/s)  LR: 1.000e-04  Data: 1.384 (4.594)
Train: 0 [   4/2502 (  0%)]  Loss:  6.944591 (6.9700)  Time: 0.173s, 2953.10/s  (4.519s,  113.31/s)  LR: 1.000e-04  Data: 0.027 (3.680)
Train: 0 [   5/2502 (  0%)]  Loss:  6.934566 (6.9641)  Time: 0.175s, 2919.27/s  (3.795s,  134.92/s)  LR: 1.000e-04  Data: 0.029 (3.072)
Train: 0 [   6/2502 (  0%)]  Loss:  6.959271 (6.9634)  Time: 0.172s, 2979.80/s  (3.277s,  156.23/s)  LR: 1.000e-04  Data: 0.027 (2.637)
Train: 0 [   7/2502 (  0%)]  Loss:  6.982008 (6.9657)  Time: 2.595s,  197.27/s  (3.192s,  160.40/s)  LR: 1.000e-04  Data: 2.411 (2.609)
Train: 0 [   8/2502 (  0%)]  Loss:  6.961213 (6.9652)  Time: 0.172s, 2969.96/s  (2.857s,  179.24/s)  LR: 1.000e-04  Data: 0.025 (2.322)
Train: 0 [   9/2502 (  0%)]  Loss:  6.969567 (6.9657)  Time: 0.173s, 2966.07/s  (2.588s,  197.83/s)  LR: 1.000e-04  Data: 0.027 (2.092)
Train: 0 [  10/2502 (  0%)]  Loss:  6.969846 (6.9660)  Time: 0.170s, 3007.93/s  (2.368s,  216.19/s)  LR: 1.000e-04  Data: 0.025 (1.904)
Train: 0 [  11/2502 (  0%)]  Loss:  6.960484 (6.9656)  Time: 2.690s,  190.36/s  (2.395s,  213.77/s)  LR: 1.000e-04  Data: 2.498 (1.954)
Train: 0 [  12/2502 (  0%)]  Loss:  6.958784 (6.9650)  Time: 0.181s, 2823.56/s  (2.225s,  230.13/s)  LR: 1.000e-04  Data: 0.030 (1.806)
Train: 0 [  13/2502 (  1%)]  Loss:  6.971075 (6.9655)  Time: 0.172s, 2974.92/s  (2.078s,  246.37/s)  LR: 1.000e-04  Data: 0.026 (1.679)
Train: 0 [  14/2502 (  1%)]  Loss:  6.969375 (6.9657)  Time: 0.172s, 2969.26/s  (1.951s,  262.41/s)  LR: 1.000e-04  Data: 0.028 (1.569)
Train: 0 [  15/2502 (  1%)]  Loss:  6.963780 (6.9656)  Time: 4.533s,  112.96/s  (2.112s,  242.37/s)  LR: 1.000e-04  Data: 2.975 (1.656)
Train: 0 [  16/2502 (  1%)]  Loss:  6.941864 (6.9642)  Time: 0.172s, 2971.78/s  (1.998s,  256.21/s)  LR: 1.000e-04  Data: 0.026 (1.561)
Train: 0 [  17/2502 (  1%)]  Loss:  6.961836 (6.9641)  Time: 0.169s, 3029.59/s  (1.897s,  269.94/s)  LR: 1.000e-04  Data: 0.024 (1.475)
Train: 0 [  18/2502 (  1%)]  Loss:  6.958797 (6.9638)  Time: 0.170s, 3020.52/s  (1.806s,  283.53/s)  LR: 1.000e-04  Data: 0.026 (1.399)
Train: 0 [  19/2502 (  1%)]  Loss:  6.962678 (6.9638)  Time: 4.103s,  124.78/s  (1.921s,  266.57/s)  LR: 1.000e-04  Data: 3.765 (1.517)
Train: 0 [  20/2502 (  1%)]  Loss:  6.957149 (6.9634)  Time: 1.514s,  338.13/s  (1.901s,  269.28/s)  LR: 1.000e-04  Data: 0.023 (1.446)
Train: 0 [  21/2502 (  1%)]  Loss:  6.952084 (6.9629)  Time: 0.172s, 2977.07/s  (1.823s,  280.90/s)  LR: 1.000e-04  Data: 0.026 (1.381)
Train: 0 [  22/2502 (  1%)]  Loss:  6.969675 (6.9632)  Time: 0.172s, 2976.98/s  (1.751s,  292.41/s)  LR: 1.000e-04  Data: 0.028 (1.323)
Train: 0 [  23/2502 (  1%)]  Loss:  6.954693 (6.9629)  Time: 6.078s,   84.23/s  (1.931s,  265.11/s)  LR: 1.000e-04  Data: 5.897 (1.513)
Train: 0 [  24/2502 (  1%)]  Loss:  6.961024 (6.9628)  Time: 0.539s,  950.09/s  (1.876s,  272.98/s)  LR: 1.000e-04  Data: 0.069 (1.455)
Train: 0 [  25/2502 (  1%)]  Loss:  6.952662 (6.9624)  Time: 0.176s, 2912.56/s  (1.810s,  282.84/s)  LR: 1.000e-04  Data: 0.029 (1.401)
Train: 0 [  26/2502 (  1%)]  Loss:  6.978289 (6.9630)  Time: 0.169s, 3037.41/s  (1.749s,  292.67/s)  LR: 1.000e-04  Data: 0.024 (1.350)
Train: 0 [  27/2502 (  1%)]  Loss:  6.988295 (6.9639)  Time: 4.858s,  105.40/s  (1.860s,  275.21/s)  LR: 1.000e-04  Data: 4.675 (1.468)
Train: 0 [  28/2502 (  1%)]  Loss:  6.967131 (6.9640)  Time: 0.620s,  826.00/s  (1.818s,  281.69/s)  LR: 1.000e-04  Data: 0.022 (1.419)
Train: 0 [  29/2502 (  1%)]  Loss:  6.964517 (6.9640)  Time: 0.171s, 3000.65/s  (1.763s,  290.46/s)  LR: 1.000e-04  Data: 0.025 (1.372)
Train: 0 [  30/2502 (  1%)]  Loss:  6.952867 (6.9637)  Time: 0.169s, 3037.43/s  (1.711s,  299.19/s)  LR: 1.000e-04  Data: 0.023 (1.329)
Train: 0 [  31/2502 (  1%)]  Loss:  6.945812 (6.9631)  Time: 3.259s,  157.13/s  (1.760s,  290.97/s)  LR: 1.000e-04  Data: 3.074 (1.383)
Train: 0 [  32/2502 (  1%)]  Loss:  6.956520 (6.9629)  Time: 1.360s,  376.56/s  (1.748s,  292.98/s)  LR: 1.000e-04  Data: 0.024 (1.342)
Train: 0 [  33/2502 (  1%)]  Loss:  6.969265 (6.9631)  Time: 0.168s, 3046.62/s  (1.701s,  300.99/s)  LR: 1.000e-04  Data: 0.023 (1.303)
Train: 0 [  34/2502 (  1%)]  Loss:  6.982956 (6.9637)  Time: 0.174s, 2950.14/s  (1.657s,  308.91/s)  LR: 1.000e-04  Data: 0.027 (1.267)
Train: 0 [  35/2502 (  1%)]  Loss:  6.971451 (6.9639)  Time: 4.216s,  121.44/s  (1.729s,  296.21/s)  LR: 1.000e-04  Data: 4.031 (1.343)
Train: 0 [  36/2502 (  1%)]  Loss:  6.977084 (6.9642)  Time: 0.179s, 2852.38/s  (1.687s,  303.56/s)  LR: 1.000e-04  Data: 0.024 (1.308)
Train: 0 [  37/2502 (  1%)]  Loss:  6.965768 (6.9643)  Time: 0.173s, 2965.73/s  (1.647s,  310.91/s)  LR: 1.000e-04  Data: 0.027 (1.274)
Train: 0 [  38/2502 (  2%)]  Loss:  6.964084 (6.9643)  Time: 1.518s,  337.28/s  (1.643s,  311.53/s)  LR: 1.000e-04  Data: 1.374 (1.277)
Train: 0 [  39/2502 (  2%)]  Loss:  6.955112 (6.9640)  Time: 7.348s,   69.68/s  (1.786s,  286.66/s)  LR: 1.000e-04  Data: 7.166 (1.424)
Train: 0 [  40/2502 (  2%)]  Loss:  6.952865 (6.9638)  Time: 0.181s, 2826.55/s  (1.747s,  293.08/s)  LR: 1.000e-04  Data: 0.025 (1.390)
Train: 0 [  41/2502 (  2%)]  Loss:  6.937540 (6.9631)  Time: 0.169s, 3022.16/s  (1.709s,  299.52/s)  LR: 1.000e-04  Data: 0.026 (1.357)
Train: 0 [  42/2502 (  2%)]  Loss:  6.965847 (6.9632)  Time: 1.550s,  330.42/s  (1.706s,  300.17/s)  LR: 1.000e-04  Data: 1.405 (1.358)
Train: 0 [  43/2502 (  2%)]  Loss:  6.981534 (6.9636)  Time: 6.680s,   76.64/s  (1.819s,  281.51/s)  LR: 1.000e-04  Data: 6.507 (1.475)
Train: 0 [  44/2502 (  2%)]  Loss:  6.957520 (6.9635)  Time: 0.175s, 2920.87/s  (1.782s,  287.28/s)  LR: 1.000e-04  Data: 0.025 (1.443)
Train: 0 [  45/2502 (  2%)]  Loss:  6.951066 (6.9632)  Time: 0.171s, 2998.47/s  (1.747s,  293.04/s)  LR: 1.000e-04  Data: 0.027 (1.412)
Train: 0 [  46/2502 (  2%)]  Loss:  6.957343 (6.9631)  Time: 0.171s, 2986.75/s  (1.714s,  298.78/s)  LR: 1.000e-04  Data: 0.028 (1.383)
Train: 0 [  47/2502 (  2%)]  Loss:  6.968235 (6.9632)  Time: 8.032s,   63.74/s  (1.845s,  277.46/s)  LR: 1.000e-04  Data: 7.849 (1.518)
Train: 0 [  48/2502 (  2%)]  Loss:  6.962993 (6.9632)  Time: 0.176s, 2903.99/s  (1.811s,  282.68/s)  LR: 1.000e-04  Data: 0.023 (1.487)
Train: 0 [  49/2502 (  2%)]  Loss:  6.949434 (6.9629)  Time: 0.174s, 2942.09/s  (1.778s,  287.89/s)  LR: 1.000e-04  Data: 0.022 (1.458)
Train: 0 [  50/2502 (  2%)]  Loss:  6.966413 (6.9630)  Time: 0.170s, 3003.99/s  (1.747s,  293.08/s)  LR: 1.000e-04  Data: 0.022 (1.430)
Train: 0 [  51/2502 (  2%)]  Loss:  6.955700 (6.9628)  Time: 7.747s,   66.09/s  (1.862s,  274.92/s)  LR: 1.000e-04  Data: 7.563 (1.548)
Train: 0 [  52/2502 (  2%)]  Loss:  6.970485 (6.9630)  Time: 0.174s, 2938.83/s  (1.830s,  279.71/s)  LR: 1.000e-04  Data: 0.025 (1.519)
Train: 0 [  53/2502 (  2%)]  Loss:  6.967023 (6.9631)  Time: 0.290s, 1768.01/s  (1.802s,  284.14/s)  LR: 1.000e-04  Data: 0.024 (1.491)
Train: 0 [  54/2502 (  2%)]  Loss:  6.967191 (6.9631)  Time: 0.168s, 3056.02/s  (1.772s,  288.90/s)  LR: 1.000e-04  Data: 0.022 (1.464)
Train: 0 [  55/2502 (  2%)]  Loss:  6.981799 (6.9635)  Time: 8.420s,   60.81/s  (1.891s,  270.76/s)  LR: 1.000e-04  Data: 8.236 (1.585)
Train: 0 [  56/2502 (  2%)]  Loss:  6.963726 (6.9635)  Time: 0.179s, 2862.74/s  (1.861s,  275.13/s)  LR: 1.000e-04  Data: 0.030 (1.558)
Train: 0 [  57/2502 (  2%)]  Loss:  6.957002 (6.9634)  Time: 0.173s, 2967.84/s  (1.832s,  279.51/s)  LR: 1.000e-04  Data: 0.026 (1.532)
Train: 0 [  58/2502 (  2%)]  Loss:  6.952419 (6.9632)  Time: 0.171s, 3000.51/s  (1.804s,  283.87/s)  LR: 1.000e-04  Data: 0.026 (1.506)
Train: 0 [  59/2502 (  2%)]  Loss:  6.992366 (6.9637)  Time: 8.673s,   59.03/s  (1.918s,  266.93/s)  LR: 1.000e-04  Data: 8.496 (1.623)
Train: 0 [  60/2502 (  2%)]  Loss:  6.977783 (6.9639)  Time: 0.186s, 2757.34/s  (1.890s,  270.94/s)  LR: 1.000e-04  Data: 0.024 (1.596)
Train: 0 [  61/2502 (  2%)]  Loss:  6.964696 (6.9639)  Time: 0.172s, 2978.42/s  (1.862s,  274.97/s)  LR: 1.000e-04  Data: 0.024 (1.571)
Train: 0 [  62/2502 (  2%)]  Loss:  6.948338 (6.9637)  Time: 0.171s, 2991.65/s  (1.835s,  278.99/s)  LR: 1.000e-04  Data: 0.027 (1.547)
Train: 0 [  63/2502 (  3%)]  Loss:  6.942568 (6.9633)  Time: 9.667s,   52.97/s  (1.958s,  261.55/s)  LR: 1.000e-04  Data: 9.488 (1.671)
Train: 0 [  64/2502 (  3%)]  Loss:  6.953150 (6.9632)  Time: 0.174s, 2938.57/s  (1.930s,  265.27/s)  LR: 1.000e-04  Data: 0.028 (1.645)
Train: 0 [  65/2502 (  3%)]  Loss:  6.970033 (6.9633)  Time: 1.098s,  466.47/s  (1.918s,  267.01/s)  LR: 1.000e-04  Data: 0.025 (1.621)
Train: 0 [  66/2502 (  3%)]  Loss:  6.966251 (6.9633)  Time: 0.172s, 2972.21/s  (1.891s,  270.69/s)  LR: 1.000e-04  Data: 0.024 (1.597)
Train: 0 [  67/2502 (  3%)]  Loss:  6.944946 (6.9631)  Time: 9.778s,   52.36/s  (2.007s,  255.05/s)  LR: 1.000e-04  Data: 9.596 (1.715)
Train: 0 [  68/2502 (  3%)]  Loss:  6.986402 (6.9634)  Time: 0.172s, 2973.46/s  (1.981s,  258.48/s)  LR: 1.000e-04  Data: 0.025 (1.690)
Train: 0 [  69/2502 (  3%)]  Loss:  6.970648 (6.9635)  Time: 0.745s,  687.30/s  (1.963s,  260.80/s)  LR: 1.000e-04  Data: 0.027 (1.666)
Train: 0 [  70/2502 (  3%)]  Loss:  6.984050 (6.9638)  Time: 0.176s, 2915.73/s  (1.938s,  264.19/s)  LR: 1.000e-04  Data: 0.024 (1.643)
Train: 0 [  71/2502 (  3%)]  Loss:  6.957914 (6.9637)  Time: 10.452s,   48.98/s  (2.056s,  249.00/s)  LR: 1.000e-04  Data: 10.279 (1.763)
Train: 0 [  72/2502 (  3%)]  Loss:  6.948569 (6.9635)  Time: 0.175s, 2932.82/s  (2.030s,  252.16/s)  LR: 1.000e-04  Data: 0.021 (1.739)
Train: 0 [  73/2502 (  3%)]  Loss:  6.970214 (6.9636)  Time: 0.173s, 2967.99/s  (2.005s,  255.31/s)  LR: 1.000e-04  Data: 0.027 (1.716)
Train: 0 [  74/2502 (  3%)]  Loss:  6.948018 (6.9634)  Time: 0.179s, 2861.98/s  (1.981s,  258.45/s)  LR: 1.000e-04  Data: 0.034 (1.694)
Train: 0 [  75/2502 (  3%)]  Loss:  6.944520 (6.9631)  Time: 6.910s,   74.09/s  (2.046s,  250.26/s)  LR: 1.000e-04  Data: 6.735 (1.760)
Train: 0 [  76/2502 (  3%)]  Loss:  6.958012 (6.9631)  Time: 0.168s, 3045.53/s  (2.021s,  253.28/s)  LR: 1.000e-04  Data: 0.020 (1.738)
Train: 0 [  77/2502 (  3%)]  Loss:  6.947339 (6.9629)  Time: 0.168s, 3049.12/s  (1.998s,  256.29/s)  LR: 1.000e-04  Data: 0.024 (1.716)
Train: 0 [  78/2502 (  3%)]  Loss:  6.951068 (6.9627)  Time: 0.168s, 3038.90/s  (1.975s,  259.30/s)  LR: 1.000e-04  Data: 0.025 (1.694)
Train: 0 [  79/2502 (  3%)]  Loss:  6.975019 (6.9629)  Time: 8.189s,   62.52/s  (2.052s,  249.48/s)  LR: 1.000e-04  Data: 8.016 (1.773)
Train: 0 [  80/2502 (  3%)]  Loss:  6.970722 (6.9630)  Time: 0.184s, 2780.08/s  (2.029s,  252.32/s)  LR: 1.000e-04  Data: 0.026 (1.752)
Train: 0 [  81/2502 (  3%)]  Loss:  6.958662 (6.9629)  Time: 0.173s, 2965.40/s  (2.007s,  255.16/s)  LR: 1.000e-04  Data: 0.028 (1.731)
Train: 0 [  82/2502 (  3%)]  Loss:  6.955110 (6.9628)  Time: 0.169s, 3031.94/s  (1.984s,  258.01/s)  LR: 1.000e-04  Data: 0.021 (1.710)
Train: 0 [  83/2502 (  3%)]  Loss:  6.973114 (6.9629)  Time: 10.933s,   46.83/s  (2.091s,  244.87/s)  LR: 1.000e-04  Data: 10.691 (1.817)
Train: 0 [  84/2502 (  3%)]  Loss:  6.952305 (6.9628)  Time: 0.177s, 2893.80/s  (2.068s,  247.53/s)  LR: 1.000e-04  Data: 0.028 (1.796)
Train: 0 [  85/2502 (  3%)]  Loss:  6.937451 (6.9625)  Time: 0.172s, 2976.76/s  (2.046s,  250.20/s)  LR: 1.000e-04  Data: 0.022 (1.775)
Train: 0 [  86/2502 (  3%)]  Loss:  6.959646 (6.9625)  Time: 0.593s,  863.16/s  (2.030s,  252.26/s)  LR: 1.000e-04  Data: 0.028 (1.755)
Train: 0 [  87/2502 (  3%)]  Loss:  6.964603 (6.9625)  Time: 14.556s,   35.18/s  (2.172s,  235.73/s)  LR: 1.000e-04  Data: 14.122 (1.896)
Train: 0 [  88/2502 (  4%)]  Loss:  6.956335 (6.9624)  Time: 0.172s, 2979.17/s  (2.150s,  238.19/s)  LR: 1.000e-04  Data: 0.026 (1.875)
Train: 0 [  89/2502 (  4%)]  Loss:  6.954488 (6.9624)  Time: 0.167s, 3057.26/s  (2.128s,  240.66/s)  LR: 1.000e-04  Data: 0.024 (1.854)
Train: 0 [  90/2502 (  4%)]  Loss:  6.956669 (6.9623)  Time: 1.801s,  284.28/s  (2.124s,  241.06/s)  LR: 1.000e-04  Data: 0.031 (1.834)
Train: 0 [  91/2502 (  4%)]  Loss:  6.950826 (6.9622)  Time: 13.539s,   37.82/s  (2.248s,  227.76/s)  LR: 1.000e-04  Data: 13.029 (1.956)
Train: 0 [  92/2502 (  4%)]  Loss:  6.944111 (6.9620)  Time: 0.169s, 3027.85/s  (2.226s,  230.05/s)  LR: 1.000e-04  Data: 0.024 (1.935)
Train: 0 [  93/2502 (  4%)]  Loss:  6.949656 (6.9618)  Time: 0.168s, 3040.71/s  (2.204s,  232.33/s)  LR: 1.000e-04  Data: 0.025 (1.915)
Train: 0 [  94/2502 (  4%)]  Loss:  6.938144 (6.9616)  Time: 4.048s,  126.47/s  (2.223s,  230.30/s)  LR: 1.000e-04  Data: 1.681 (1.912)
Train: 0 [  95/2502 (  4%)]  Loss:  6.962652 (6.9616)  Time: 12.629s,   40.54/s  (2.332s,  219.59/s)  LR: 1.000e-04  Data: 12.446 (2.022)
Train: 0 [  96/2502 (  4%)]  Loss:  6.946769 (6.9615)  Time: 0.188s, 2720.84/s  (2.309s,  221.70/s)  LR: 1.000e-04  Data: 0.026 (2.001)
Train: 0 [  97/2502 (  4%)]  Loss:  6.941363 (6.9612)  Time: 0.170s, 3019.16/s  (2.288s,  223.81/s)  LR: 1.000e-04  Data: 0.025 (1.981)
Train: 0 [  98/2502 (  4%)]  Loss:  6.948330 (6.9611)  Time: 2.875s,  178.10/s  (2.294s,  223.23/s)  LR: 1.000e-04  Data: 2.242 (1.984)
Train: 0 [  99/2502 (  4%)]  Loss:  6.989329 (6.9614)  Time: 11.199s,   45.72/s  (2.383s,  214.89/s)  LR: 1.000e-04  Data: 11.021 (2.074)
