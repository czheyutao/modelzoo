/data/softws_up/miniconda3/envs/vae/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0214 18:21:31.212750 140678964155328 torch/distributed/run.py:779] 
W0214 18:21:31.212750 140678964155328 torch/distributed/run.py:779] *****************************************
W0214 18:21:31.212750 140678964155328 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0214 18:21:31.212750 140678964155328 torch/distributed/run.py:779] *****************************************
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
Model seresnet152 created, param count: 66821848
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bilinear
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
NVIDIA APEX not installed. AMP off.
Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.
Scheduled epochs: 160
Train: 0 [   0/10009 (  0%)]  Loss:  6.961930 (6.9619)  Time: 7.933s,   16.14/s  (7.933s,   16.14/s)  LR: 1.000e-04  Data: 6.011 (6.011)
Train: 0 [   1/10009 (  0%)]  Loss:  6.972290 (6.9671)  Time: 0.240s,  532.91/s  (4.087s,   31.32/s)  LR: 1.000e-04  Data: 0.009 (3.010)
Train: 0 [   2/10009 (  0%)]  Loss:  7.001422 (6.9785)  Time: 0.158s,  808.40/s  (2.777s,   46.09/s)  LR: 1.000e-04  Data: 0.007 (2.009)
Train: 0 [   3/10009 (  0%)]  Loss:  6.973666 (6.9773)  Time: 3.621s,   35.35/s  (2.988s,   42.84/s)  LR: 1.000e-04  Data: 3.264 (2.323)
Train: 0 [   4/10009 (  0%)]  Loss:  6.975708 (6.9770)  Time: 0.162s,  788.27/s  (2.423s,   52.83/s)  LR: 1.000e-04  Data: 0.007 (1.859)
Train: 0 [   5/10009 (  0%)]  Loss:  7.033890 (6.9865)  Time: 0.153s,  835.17/s  (2.045s,   62.60/s)  LR: 1.000e-04  Data: 0.005 (1.550)
Train: 0 [   6/10009 (  0%)]  Loss:  7.011969 (6.9901)  Time: 0.160s,  801.06/s  (1.775s,   72.10/s)  LR: 1.000e-04  Data: 0.006 (1.330)
Train: 0 [   7/10009 (  0%)]  Loss:  6.983004 (6.9892)  Time: 3.830s,   33.42/s  (2.032s,   62.99/s)  LR: 1.000e-04  Data: 3.612 (1.615)
Train: 0 [   8/10009 (  0%)]  Loss:  7.006219 (6.9911)  Time: 0.170s,  755.15/s  (1.825s,   70.13/s)  LR: 1.000e-04  Data: 0.006 (1.436)
Train: 0 [   9/10009 (  0%)]  Loss:  6.897555 (6.9818)  Time: 0.159s,  805.75/s  (1.659s,   77.17/s)  LR: 1.000e-04  Data: 0.006 (1.293)
Train: 0 [  10/10009 (  0%)]  Loss:  6.980927 (6.9817)  Time: 0.156s,  821.14/s  (1.522s,   84.10/s)  LR: 1.000e-04  Data: 0.006 (1.176)
Train: 0 [  11/10009 (  0%)]  Loss:  6.979600 (6.9815)  Time: 5.781s,   22.14/s  (1.877s,   68.20/s)  LR: 1.000e-04  Data: 5.383 (1.527)
Train: 0 [  12/10009 (  0%)]  Loss:  7.052237 (6.9870)  Time: 0.173s,  741.53/s  (1.746s,   73.32/s)  LR: 1.000e-04  Data: 0.008 (1.410)
Train: 0 [  13/10009 (  0%)]  Loss:  7.008914 (6.9885)  Time: 0.939s,  136.33/s  (1.688s,   75.82/s)  LR: 1.000e-04  Data: 0.008 (1.310)
Train: 0 [  14/10009 (  0%)]  Loss:  6.980019 (6.9880)  Time: 0.236s,  543.50/s  (1.591s,   80.43/s)  LR: 1.000e-04  Data: 0.008 (1.223)
Train: 0 [  15/10009 (  0%)]  Loss:  6.969904 (6.9868)  Time: 6.788s,   18.86/s  (1.916s,   66.80/s)  LR: 1.000e-04  Data: 4.335 (1.418)
Train: 0 [  16/10009 (  0%)]  Loss:  6.924595 (6.9832)  Time: 0.168s,  762.05/s  (1.813s,   70.59/s)  LR: 1.000e-04  Data: 0.010 (1.335)
Train: 0 [  17/10009 (  0%)]  Loss:  6.976943 (6.9828)  Time: 0.159s,  805.24/s  (1.721s,   74.36/s)  LR: 1.000e-04  Data: 0.008 (1.261)
Train: 0 [  18/10009 (  0%)]  Loss:  7.016878 (6.9846)  Time: 0.165s,  776.86/s  (1.639s,   78.07/s)  LR: 1.000e-04  Data: 0.006 (1.195)
Train: 0 [  19/10009 (  0%)]  Loss:  6.929554 (6.9819)  Time: 6.374s,   20.08/s  (1.876s,   68.22/s)  LR: 1.000e-04  Data: 4.915 (1.381)
Train: 0 [  20/10009 (  0%)]  Loss:  6.982247 (6.9819)  Time: 0.168s,  762.73/s  (1.795s,   71.32/s)  LR: 1.000e-04  Data: 0.007 (1.316)
Train: 0 [  21/10009 (  0%)]  Loss:  6.952079 (6.9805)  Time: 0.165s,  774.05/s  (1.721s,   74.38/s)  LR: 1.000e-04  Data: 0.011 (1.256)
Train: 0 [  22/10009 (  0%)]  Loss:  6.990510 (6.9810)  Time: 1.068s,  119.91/s  (1.692s,   75.63/s)  LR: 1.000e-04  Data: 0.007 (1.202)
Train: 0 [  23/10009 (  0%)]  Loss:  7.029902 (6.9830)  Time: 4.507s,   28.40/s  (1.810s,   70.73/s)  LR: 1.000e-04  Data: 3.358 (1.292)
Train: 0 [  24/10009 (  0%)]  Loss:  6.978334 (6.9828)  Time: 0.170s,  751.23/s  (1.744s,   73.39/s)  LR: 1.000e-04  Data: 0.007 (1.240)
Train: 0 [  25/10009 (  0%)]  Loss:  7.010652 (6.9839)  Time: 0.155s,  825.12/s  (1.683s,   76.06/s)  LR: 1.000e-04  Data: 0.008 (1.193)
Train: 0 [  26/10009 (  0%)]  Loss:  7.003295 (6.9846)  Time: 0.156s,  821.44/s  (1.626s,   78.70/s)  LR: 1.000e-04  Data: 0.008 (1.149)
Train: 0 [  27/10009 (  0%)]  Loss:  7.028039 (6.9862)  Time: 5.274s,   24.27/s  (1.757s,   72.86/s)  LR: 1.000e-04  Data: 4.679 (1.275)
Train: 0 [  28/10009 (  0%)]  Loss:  6.983701 (6.9861)  Time: 0.157s,  812.89/s  (1.702s,   75.23/s)  LR: 1.000e-04  Data: 0.007 (1.231)
Train: 0 [  29/10009 (  0%)]  Loss:  6.966585 (6.9854)  Time: 0.157s,  814.99/s  (1.650s,   77.57/s)  LR: 1.000e-04  Data: 0.008 (1.191)
Train: 0 [  30/10009 (  0%)]  Loss:  6.931809 (6.9837)  Time: 0.158s,  807.80/s  (1.602s,   79.90/s)  LR: 1.000e-04  Data: 0.007 (1.152)
Train: 0 [  31/10009 (  0%)]  Loss:  7.005716 (6.9844)  Time: 5.710s,   22.42/s  (1.730s,   73.98/s)  LR: 1.000e-04  Data: 4.880 (1.269)
Train: 0 [  32/10009 (  0%)]  Loss:  6.986957 (6.9845)  Time: 0.162s,  791.20/s  (1.683s,   76.06/s)  LR: 1.000e-04  Data: 0.007 (1.231)
Train: 0 [  33/10009 (  0%)]  Loss:  7.000856 (6.9849)  Time: 0.158s,  809.49/s  (1.638s,   78.15/s)  LR: 1.000e-04  Data: 0.009 (1.195)
Train: 0 [  34/10009 (  0%)]  Loss:  6.982075 (6.9849)  Time: 0.157s,  814.42/s  (1.596s,   80.22/s)  LR: 1.000e-04  Data: 0.008 (1.161)
Train: 0 [  35/10009 (  0%)]  Loss:  7.060724 (6.9870)  Time: 5.032s,   25.44/s  (1.691s,   75.69/s)  LR: 1.000e-04  Data: 4.215 (1.246)
Train: 0 [  36/10009 (  0%)]  Loss:  6.964330 (6.9864)  Time: 0.161s,  795.62/s  (1.650s,   77.59/s)  LR: 1.000e-04  Data: 0.007 (1.212)
Train: 0 [  37/10009 (  0%)]  Loss:  6.997836 (6.9867)  Time: 0.155s,  827.80/s  (1.610s,   79.48/s)  LR: 1.000e-04  Data: 0.006 (1.180)
Train: 0 [  38/10009 (  0%)]  Loss:  6.990566 (6.9868)  Time: 0.156s,  821.07/s  (1.573s,   81.37/s)  LR: 1.000e-04  Data: 0.006 (1.150)
Train: 0 [  39/10009 (  0%)]  Loss:  7.022923 (6.9877)  Time: 5.503s,   23.26/s  (1.671s,   76.59/s)  LR: 1.000e-04  Data: 4.528 (1.235)
Train: 0 [  40/10009 (  0%)]  Loss:  7.006322 (6.9881)  Time: 0.155s,  826.68/s  (1.634s,   78.32/s)  LR: 1.000e-04  Data: 0.007 (1.205)
Train: 0 [  41/10009 (  0%)]  Loss:  6.963879 (6.9875)  Time: 0.154s,  829.23/s  (1.599s,   80.04/s)  LR: 1.000e-04  Data: 0.008 (1.176)
Train: 0 [  42/10009 (  0%)]  Loss:  6.955360 (6.9868)  Time: 0.156s,  819.09/s  (1.566s,   81.76/s)  LR: 1.000e-04  Data: 0.007 (1.149)
Train: 0 [  43/10009 (  0%)]  Loss:  6.998642 (6.9871)  Time: 5.259s,   24.34/s  (1.649s,   77.60/s)  LR: 1.000e-04  Data: 4.473 (1.225)
Train: 0 [  44/10009 (  0%)]  Loss:  6.991117 (6.9871)  Time: 0.170s,  753.63/s  (1.617s,   79.18/s)  LR: 1.000e-04  Data: 0.006 (1.198)
Train: 0 [  45/10009 (  0%)]  Loss:  6.996868 (6.9874)  Time: 0.160s,  799.96/s  (1.585s,   80.76/s)  LR: 1.000e-04  Data: 0.008 (1.172)
Train: 0 [  46/10009 (  0%)]  Loss:  7.031407 (6.9883)  Time: 0.156s,  818.56/s  (1.555s,   82.34/s)  LR: 1.000e-04  Data: 0.006 (1.147)
Train: 0 [  47/10009 (  0%)]  Loss:  6.974324 (6.9880)  Time: 3.695s,   34.64/s  (1.599s,   80.04/s)  LR: 1.000e-04  Data: 3.041 (1.186)
Train: 0 [  48/10009 (  0%)]  Loss:  7.009131 (6.9884)  Time: 2.252s,   56.83/s  (1.612s,   79.38/s)  LR: 1.000e-04  Data: 0.006 (1.162)
Train: 0 [  49/10009 (  0%)]  Loss:  6.945957 (6.9876)  Time: 0.164s,  781.41/s  (1.584s,   80.83/s)  LR: 1.000e-04  Data: 0.009 (1.139)
Train: 0 [  50/10009 (  0%)]  Loss:  6.993369 (6.9877)  Time: 0.167s,  767.84/s  (1.556s,   82.28/s)  LR: 1.000e-04  Data: 0.014 (1.117)
Train: 0 [  51/10009 (  1%)]  Loss:  7.047690 (6.9889)  Time: 2.927s,   43.73/s  (1.582s,   80.91/s)  LR: 1.000e-04  Data: 2.093 (1.136)
Train: 0 [  52/10009 (  1%)]  Loss:  6.969270 (6.9885)  Time: 1.777s,   72.05/s  (1.586s,   80.72/s)  LR: 1.000e-04  Data: 0.009 (1.115)
Train: 0 [  53/10009 (  1%)]  Loss:  6.953430 (6.9878)  Time: 0.160s,  800.54/s  (1.559s,   82.08/s)  LR: 1.000e-04  Data: 0.008 (1.094)
Train: 0 [  54/10009 (  1%)]  Loss:  6.999937 (6.9881)  Time: 0.166s,  769.69/s  (1.534s,   83.44/s)  LR: 1.000e-04  Data: 0.012 (1.074)
Train: 0 [  55/10009 (  1%)]  Loss:  6.967853 (6.9877)  Time: 3.244s,   39.45/s  (1.565s,   81.81/s)  LR: 1.000e-04  Data: 0.997 (1.073)
Train: 0 [  56/10009 (  1%)]  Loss:  6.985909 (6.9877)  Time: 0.675s,  189.49/s  (1.549s,   82.64/s)  LR: 1.000e-04  Data: 0.006 (1.054)
Train: 0 [  57/10009 (  1%)]  Loss:  6.979168 (6.9875)  Time: 0.167s,  767.65/s  (1.525s,   83.93/s)  LR: 1.000e-04  Data: 0.008 (1.036)
Train: 0 [  58/10009 (  1%)]  Loss:  6.988963 (6.9875)  Time: 0.161s,  797.05/s  (1.502s,   85.22/s)  LR: 1.000e-04  Data: 0.007 (1.019)
Train: 0 [  59/10009 (  1%)]  Loss:  6.954237 (6.9870)  Time: 4.728s,   27.07/s  (1.556s,   82.27/s)  LR: 1.000e-04  Data: 2.337 (1.041)
Train: 0 [  60/10009 (  1%)]  Loss:  7.000035 (6.9872)  Time: 0.916s,  139.79/s  (1.545s,   82.83/s)  LR: 1.000e-04  Data: 0.005 (1.024)
Train: 0 [  61/10009 (  1%)]  Loss:  6.998306 (6.9874)  Time: 0.156s,  818.56/s  (1.523s,   84.05/s)  LR: 1.000e-04  Data: 0.006 (1.007)
Train: 0 [  62/10009 (  1%)]  Loss:  6.998906 (6.9876)  Time: 0.164s,  781.06/s  (1.501s,   85.26/s)  LR: 1.000e-04  Data: 0.008 (0.992)
Train: 0 [  63/10009 (  1%)]  Loss:  6.966119 (6.9872)  Time: 4.682s,   27.34/s  (1.551s,   82.53/s)  LR: 1.000e-04  Data: 2.237 (1.011)
Train: 0 [  64/10009 (  1%)]  Loss:  6.972655 (6.9870)  Time: 0.604s,  212.08/s  (1.536s,   83.31/s)  LR: 1.000e-04  Data: 0.006 (0.996)
Train: 0 [  65/10009 (  1%)]  Loss:  6.938907 (6.9863)  Time: 0.164s,  781.05/s  (1.516s,   84.45/s)  LR: 1.000e-04  Data: 0.007 (0.981)
Train: 0 [  66/10009 (  1%)]  Loss:  6.971238 (6.9861)  Time: 0.163s,  785.21/s  (1.495s,   85.59/s)  LR: 1.000e-04  Data: 0.008 (0.966)
Train: 0 [  67/10009 (  1%)]  Loss:  7.054129 (6.9871)  Time: 5.522s,   23.18/s  (1.555s,   82.33/s)  LR: 1.000e-04  Data: 3.039 (0.997)
Train: 0 [  68/10009 (  1%)]  Loss:  6.967028 (6.9868)  Time: 0.606s,  211.12/s  (1.541s,   83.07/s)  LR: 1.000e-04  Data: 0.009 (0.982)
Train: 0 [  69/10009 (  1%)]  Loss:  7.020977 (6.9872)  Time: 0.165s,  776.69/s  (1.521s,   84.14/s)  LR: 1.000e-04  Data: 0.008 (0.968)
Train: 0 [  70/10009 (  1%)]  Loss:  7.000891 (6.9874)  Time: 0.162s,  791.83/s  (1.502s,   85.21/s)  LR: 1.000e-04  Data: 0.007 (0.955)
Train: 0 [  71/10009 (  1%)]  Loss:  6.997878 (6.9876)  Time: 4.894s,   26.15/s  (1.549s,   82.62/s)  LR: 1.000e-04  Data: 2.689 (0.979)
Train: 0 [  72/10009 (  1%)]  Loss:  6.944471 (6.9870)  Time: 1.018s,  125.79/s  (1.542s,   83.01/s)  LR: 1.000e-04  Data: 0.008 (0.966)
Train: 0 [  73/10009 (  1%)]  Loss:  6.977500 (6.9869)  Time: 0.167s,  765.20/s  (1.523s,   84.02/s)  LR: 1.000e-04  Data: 0.008 (0.953)
Train: 0 [  74/10009 (  1%)]  Loss:  6.993680 (6.9870)  Time: 0.163s,  786.94/s  (1.505s,   85.04/s)  LR: 1.000e-04  Data: 0.008 (0.940)
Train: 0 [  75/10009 (  1%)]  Loss:  6.929439 (6.9862)  Time: 5.012s,   25.54/s  (1.551s,   82.51/s)  LR: 1.000e-04  Data: 4.368 (0.985)
Train: 0 [  76/10009 (  1%)]  Loss:  7.014964 (6.9866)  Time: 2.440s,   52.45/s  (1.563s,   81.90/s)  LR: 1.000e-04  Data: 0.009 (0.972)
Train: 0 [  77/10009 (  1%)]  Loss:  7.014163 (6.9869)  Time: 0.171s,  747.19/s  (1.545s,   82.84/s)  LR: 1.000e-04  Data: 0.007 (0.960)
Train: 0 [  78/10009 (  1%)]  Loss:  6.956818 (6.9865)  Time: 0.166s,  772.89/s  (1.528s,   83.79/s)  LR: 1.000e-04  Data: 0.007 (0.948)
Train: 0 [  79/10009 (  1%)]  Loss:  6.948533 (6.9861)  Time: 3.693s,   34.66/s  (1.555s,   82.33/s)  LR: 1.000e-04  Data: 2.468 (0.967)
Train: 0 [  80/10009 (  1%)]  Loss:  6.954427 (6.9857)  Time: 0.352s,  364.04/s  (1.540s,   83.13/s)  LR: 1.000e-04  Data: 0.006 (0.955)
Train: 0 [  81/10009 (  1%)]  Loss:  6.945557 (6.9852)  Time: 0.170s,  751.01/s  (1.523s,   84.04/s)  LR: 1.000e-04  Data: 0.007 (0.944)
Train: 0 [  82/10009 (  1%)]  Loss:  6.973328 (6.9850)  Time: 0.157s,  813.46/s  (1.507s,   84.96/s)  LR: 1.000e-04  Data: 0.007 (0.932)
Train: 0 [  83/10009 (  1%)]  Loss:  7.013083 (6.9854)  Time: 5.713s,   22.40/s  (1.557s,   82.22/s)  LR: 1.000e-04  Data: 3.869 (0.967)
Train: 0 [  84/10009 (  1%)]  Loss:  7.010393 (6.9857)  Time: 1.673s,   76.50/s  (1.558s,   82.15/s)  LR: 1.000e-04  Data: 0.006 (0.956)
Train: 0 [  85/10009 (  1%)]  Loss:  7.018044 (6.9861)  Time: 0.156s,  821.94/s  (1.542s,   83.02/s)  LR: 1.000e-04  Data: 0.006 (0.945)
Train: 0 [  86/10009 (  1%)]  Loss:  6.965016 (6.9858)  Time: 0.152s,  844.55/s  (1.526s,   83.89/s)  LR: 1.000e-04  Data: 0.007 (0.934)
Train: 0 [  87/10009 (  1%)]  Loss:  7.064876 (6.9867)  Time: 5.782s,   22.14/s  (1.574s,   81.31/s)  LR: 1.000e-04  Data: 2.812 (0.956)
Train: 0 [  88/10009 (  1%)]  Loss:  6.947425 (6.9863)  Time: 0.258s,  495.84/s  (1.559s,   82.08/s)  LR: 1.000e-04  Data: 0.008 (0.945)
Train: 0 [  89/10009 (  1%)]  Loss:  7.011453 (6.9865)  Time: 0.162s,  790.12/s  (1.544s,   82.91/s)  LR: 1.000e-04  Data: 0.008 (0.934)
Train: 0 [  90/10009 (  1%)]  Loss:  6.928810 (6.9859)  Time: 0.159s,  802.52/s  (1.529s,   83.73/s)  LR: 1.000e-04  Data: 0.007 (0.924)
Train: 0 [  91/10009 (  1%)]  Loss:  6.980874 (6.9859)  Time: 3.642s,   35.14/s  (1.552s,   82.49/s)  LR: 1.000e-04  Data: 2.229 (0.938)
Train: 0 [  92/10009 (  1%)]  Loss:  6.973938 (6.9857)  Time: 0.160s,  800.20/s  (1.537s,   83.30/s)  LR: 1.000e-04  Data: 0.008 (0.928)
Train: 0 [  93/10009 (  1%)]  Loss:  7.030247 (6.9862)  Time: 0.155s,  826.30/s  (1.522s,   84.10/s)  LR: 1.000e-04  Data: 0.005 (0.919)
Train: 0 [  94/10009 (  1%)]  Loss:  6.930154 (6.9856)  Time: 1.031s,  124.21/s  (1.517s,   84.39/s)  LR: 1.000e-04  Data: 0.827 (0.918)
Train: 0 [  95/10009 (  1%)]  Loss:  6.937812 (6.9851)  Time: 4.291s,   29.83/s  (1.546s,   82.81/s)  LR: 1.000e-04  Data: 1.343 (0.922)
Train: 0 [  96/10009 (  1%)]  Loss:  6.922662 (6.9845)  Time: 0.169s,  759.41/s  (1.531s,   83.58/s)  LR: 1.000e-04  Data: 0.008 (0.913)
Train: 0 [  97/10009 (  1%)]  Loss:  6.976422 (6.9844)  Time: 0.158s,  811.15/s  (1.517s,   84.35/s)  LR: 1.000e-04  Data: 0.006 (0.903)
Train: 0 [  98/10009 (  1%)]  Loss:  6.915977 (6.9837)  Time: 0.157s,  814.05/s  (1.504s,   85.12/s)  LR: 1.000e-04  Data: 0.008 (0.894)
Train: 0 [  99/10009 (  1%)]  Loss:  6.990685 (6.9838)  Time: 7.755s,   16.50/s  (1.566s,   81.72/s)  LR: 1.000e-04  Data: 2.542 (0.911)
