/data/softws_up/miniconda3/envs/vae/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
W0218 13:15:01.554822 140505234875328 torch/distributed/run.py:779] 
W0218 13:15:01.554822 140505234875328 torch/distributed/run.py:779] *****************************************
W0218 13:15:01.554822 140505234875328 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0218 13:15:01.554822 140505234875328 torch/distributed/run.py:779] *****************************************
Training in distributed mode with multiple processes, 1 GPU per process. Process 0, total 4.
Model seresnext50_32x4d created, param count: 27559896
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bilinear
	mean: (0.485, 0.456, 0.406)
	std: (0.229, 0.224, 0.225)
	crop_pct: 0.875
Training in distributed mode with multiple processes, 1 GPU per process. Process 3, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 2, total 4.
Training in distributed mode with multiple processes, 1 GPU per process. Process 1, total 4.
NVIDIA APEX not installed. AMP off.
Using torch DistributedDataParallel. Install NVIDIA Apex for Apex DDP.
Scheduled epochs: 160
Train: 0 [   0/5004 (  0%)]  Loss:  6.996330 (6.9963)  Time: 12.499s,   20.48/s  (12.499s,   20.48/s)  LR: 1.000e-04  Data: 7.918 (7.918)
Train: 0 [   1/5004 (  0%)]  Loss:  6.957313 (6.9768)  Time: 0.276s,  927.82/s  (6.387s,   40.08/s)  LR: 1.000e-04  Data: 0.018 (3.968)
Train: 0 [   2/5004 (  0%)]  Loss:  6.995407 (6.9830)  Time: 0.253s, 1010.25/s  (4.343s,   58.95/s)  LR: 1.000e-04  Data: 0.015 (2.650)
Train: 0 [   3/5004 (  0%)]  Loss:  6.979046 (6.9820)  Time: 0.255s, 1005.56/s  (3.321s,   77.09/s)  LR: 1.000e-04  Data: 0.029 (1.995)
Train: 0 [   4/5004 (  0%)]  Loss:  6.946144 (6.9748)  Time: 0.253s, 1013.82/s  (2.707s,   94.57/s)  LR: 1.000e-04  Data: 0.030 (1.602)
Train: 0 [   5/5004 (  0%)]  Loss:  6.972819 (6.9745)  Time: 0.254s, 1006.94/s  (2.298s,  111.39/s)  LR: 1.000e-04  Data: 0.032 (1.340)
Train: 0 [   6/5004 (  0%)]  Loss:  7.015577 (6.9804)  Time: 0.257s,  995.84/s  (2.007s,  127.57/s)  LR: 1.000e-04  Data: 0.034 (1.154)
Train: 0 [   7/5004 (  0%)]  Loss:  6.978463 (6.9801)  Time: 0.259s,  989.67/s  (1.788s,  143.16/s)  LR: 1.000e-04  Data: 0.033 (1.014)
Train: 0 [   8/5004 (  0%)]  Loss:  6.939237 (6.9756)  Time: 0.253s, 1012.59/s  (1.618s,  158.26/s)  LR: 1.000e-04  Data: 0.032 (0.905)
Train: 0 [   9/5004 (  0%)]  Loss:  6.976347 (6.9757)  Time: 0.259s,  989.53/s  (1.482s,  172.78/s)  LR: 1.000e-04  Data: 0.033 (0.817)
Train: 0 [  10/5004 (  0%)]  Loss:  6.975367 (6.9756)  Time: 0.251s, 1020.46/s  (1.370s,  186.89/s)  LR: 1.000e-04  Data: 0.032 (0.746)
Train: 0 [  11/5004 (  0%)]  Loss:  6.988046 (6.9767)  Time: 0.255s, 1003.45/s  (1.277s,  200.48/s)  LR: 1.000e-04  Data: 0.032 (0.687)
Train: 0 [  12/5004 (  0%)]  Loss:  6.964202 (6.9757)  Time: 0.248s, 1030.41/s  (1.198s,  213.73/s)  LR: 1.000e-04  Data: 0.020 (0.635)
Train: 0 [  13/5004 (  0%)]  Loss:  7.007107 (6.9780)  Time: 0.252s, 1017.85/s  (1.130s,  226.51/s)  LR: 1.000e-04  Data: 0.029 (0.592)
Train: 0 [  14/5004 (  0%)]  Loss:  6.989948 (6.9788)  Time: 0.672s,  380.94/s  (1.100s,  232.80/s)  LR: 1.000e-04  Data: 0.378 (0.578)
Train: 0 [  15/5004 (  0%)]  Loss:  6.920961 (6.9751)  Time: 0.248s, 1033.33/s  (1.046s,  244.64/s)  LR: 1.000e-04  Data: 0.019 (0.543)
Train: 0 [  16/5004 (  0%)]  Loss:  6.973412 (6.9750)  Time: 0.249s, 1027.33/s  (1.000s,  256.12/s)  LR: 1.000e-04  Data: 0.023 (0.512)
Train: 0 [  17/5004 (  0%)]  Loss:  6.978307 (6.9752)  Time: 0.252s, 1016.02/s  (0.958s,  267.23/s)  LR: 1.000e-04  Data: 0.027 (0.485)
Train: 0 [  18/5004 (  0%)]  Loss:  7.026443 (6.9779)  Time: 0.268s,  953.76/s  (0.922s,  277.75/s)  LR: 1.000e-04  Data: 0.029 (0.461)
Train: 0 [  19/5004 (  0%)]  Loss:  7.012311 (6.9796)  Time: 0.248s, 1030.77/s  (0.888s,  288.28/s)  LR: 1.000e-04  Data: 0.030 (0.440)
Train: 0 [  20/5004 (  0%)]  Loss:  6.968470 (6.9791)  Time: 0.261s,  980.21/s  (0.858s,  298.31/s)  LR: 1.000e-04  Data: 0.036 (0.420)
Train: 0 [  21/5004 (  0%)]  Loss:  6.974982 (6.9789)  Time: 0.253s, 1010.49/s  (0.831s,  308.18/s)  LR: 1.000e-04  Data: 0.027 (0.403)
Train: 0 [  22/5004 (  0%)]  Loss:  7.012257 (6.9804)  Time: 0.255s, 1002.83/s  (0.806s,  317.75/s)  LR: 1.000e-04  Data: 0.033 (0.386)
Train: 0 [  23/5004 (  0%)]  Loss:  6.983460 (6.9805)  Time: 0.247s, 1034.44/s  (0.782s,  327.19/s)  LR: 1.000e-04  Data: 0.025 (0.371)
Train: 0 [  24/5004 (  0%)]  Loss:  6.958388 (6.9796)  Time: 0.248s, 1032.36/s  (0.761s,  336.39/s)  LR: 1.000e-04  Data: 0.032 (0.358)
Train: 0 [  25/5004 (  0%)]  Loss:  6.943662 (6.9782)  Time: 0.473s,  541.34/s  (0.750s,  341.36/s)  LR: 1.000e-04  Data: 0.075 (0.347)
Train: 0 [  26/5004 (  1%)]  Loss:  6.977956 (6.9782)  Time: 0.310s,  825.68/s  (0.734s,  348.94/s)  LR: 1.000e-04  Data: 0.077 (0.337)
Train: 0 [  27/5004 (  1%)]  Loss:  6.967256 (6.9778)  Time: 0.251s, 1018.75/s  (0.716s,  357.33/s)  LR: 1.000e-04  Data: 0.027 (0.326)
Train: 0 [  28/5004 (  1%)]  Loss:  6.959496 (6.9772)  Time: 0.263s,  971.68/s  (0.701s,  365.29/s)  LR: 1.000e-04  Data: 0.030 (0.316)
Train: 0 [  29/5004 (  1%)]  Loss:  7.030457 (6.9790)  Time: 0.260s,  983.52/s  (0.686s,  373.11/s)  LR: 1.000e-04  Data: 0.034 (0.306)
Train: 0 [  30/5004 (  1%)]  Loss:  7.004195 (6.9798)  Time: 0.255s, 1003.51/s  (0.672s,  380.83/s)  LR: 1.000e-04  Data: 0.035 (0.298)
Train: 0 [  31/5004 (  1%)]  Loss:  7.000089 (6.9804)  Time: 0.253s, 1012.28/s  (0.659s,  388.40/s)  LR: 1.000e-04  Data: 0.034 (0.289)
Train: 0 [  32/5004 (  1%)]  Loss:  6.984026 (6.9805)  Time: 0.253s, 1011.98/s  (0.647s,  395.79/s)  LR: 1.000e-04  Data: 0.036 (0.282)
Train: 0 [  33/5004 (  1%)]  Loss:  6.991622 (6.9809)  Time: 0.255s, 1005.41/s  (0.635s,  402.97/s)  LR: 1.000e-04  Data: 0.035 (0.274)
Train: 0 [  34/5004 (  1%)]  Loss:  6.988657 (6.9811)  Time: 0.268s,  956.74/s  (0.625s,  409.75/s)  LR: 1.000e-04  Data: 0.037 (0.268)
Train: 0 [  35/5004 (  1%)]  Loss:  6.988127 (6.9813)  Time: 0.250s, 1025.88/s  (0.614s,  416.70/s)  LR: 1.000e-04  Data: 0.033 (0.261)
Train: 0 [  36/5004 (  1%)]  Loss:  6.937351 (6.9801)  Time: 0.257s,  995.58/s  (0.605s,  423.36/s)  LR: 1.000e-04  Data: 0.026 (0.255)
Train: 0 [  37/5004 (  1%)]  Loss:  7.009844 (6.9809)  Time: 0.253s, 1010.49/s  (0.595s,  429.93/s)  LR: 1.000e-04  Data: 0.031 (0.249)
Train: 0 [  38/5004 (  1%)]  Loss:  6.986161 (6.9810)  Time: 0.242s, 1059.06/s  (0.586s,  436.58/s)  LR: 1.000e-04  Data: 0.020 (0.243)
Train: 0 [  39/5004 (  1%)]  Loss:  6.981258 (6.9810)  Time: 0.259s,  987.43/s  (0.578s,  442.75/s)  LR: 1.000e-04  Data: 0.036 (0.238)
Train: 0 [  40/5004 (  1%)]  Loss:  7.000310 (6.9815)  Time: 0.257s,  996.43/s  (0.570s,  448.84/s)  LR: 1.000e-04  Data: 0.033 (0.233)
Train: 0 [  41/5004 (  1%)]  Loss:  6.948927 (6.9807)  Time: 0.248s, 1033.54/s  (0.563s,  454.97/s)  LR: 1.000e-04  Data: 0.031 (0.228)
Train: 0 [  42/5004 (  1%)]  Loss:  6.983501 (6.9808)  Time: 0.256s,  998.30/s  (0.556s,  460.80/s)  LR: 1.000e-04  Data: 0.040 (0.224)
Train: 0 [  43/5004 (  1%)]  Loss:  6.951631 (6.9801)  Time: 0.252s, 1017.31/s  (0.549s,  466.60/s)  LR: 1.000e-04  Data: 0.032 (0.219)
Train: 0 [  44/5004 (  1%)]  Loss:  7.018199 (6.9810)  Time: 0.258s,  990.44/s  (0.542s,  472.15/s)  LR: 1.000e-04  Data: 0.037 (0.215)
Train: 0 [  45/5004 (  1%)]  Loss:  6.972196 (6.9808)  Time: 0.253s, 1013.83/s  (0.536s,  477.70/s)  LR: 1.000e-04  Data: 0.029 (0.211)
Train: 0 [  46/5004 (  1%)]  Loss:  7.029274 (6.9818)  Time: 0.255s, 1003.42/s  (0.530s,  483.08/s)  LR: 1.000e-04  Data: 0.029 (0.207)
Train: 0 [  47/5004 (  1%)]  Loss:  6.947052 (6.9811)  Time: 0.256s,  999.10/s  (0.524s,  488.34/s)  LR: 1.000e-04  Data: 0.030 (0.204)
Train: 0 [  48/5004 (  1%)]  Loss:  6.992991 (6.9813)  Time: 0.259s,  987.13/s  (0.519s,  493.42/s)  LR: 1.000e-04  Data: 0.030 (0.200)
Train: 0 [  49/5004 (  1%)]  Loss:  6.940428 (6.9805)  Time: 0.249s, 1027.96/s  (0.513s,  498.61/s)  LR: 1.000e-04  Data: 0.031 (0.197)
Train: 0 [  50/5004 (  1%)]  Loss:  6.946248 (6.9798)  Time: 0.261s,  982.20/s  (0.508s,  503.47/s)  LR: 1.000e-04  Data: 0.034 (0.193)
Train: 0 [  51/5004 (  1%)]  Loss:  6.943882 (6.9791)  Time: 0.253s, 1012.89/s  (0.504s,  508.39/s)  LR: 1.000e-04  Data: 0.031 (0.190)
Train: 0 [  52/5004 (  1%)]  Loss:  6.967703 (6.9789)  Time: 0.257s,  995.65/s  (0.499s,  513.13/s)  LR: 1.000e-04  Data: 0.034 (0.187)
Train: 0 [  53/5004 (  1%)]  Loss:  6.951102 (6.9784)  Time: 0.255s, 1003.35/s  (0.494s,  517.81/s)  LR: 1.000e-04  Data: 0.033 (0.185)
Train: 0 [  54/5004 (  1%)]  Loss:  6.962504 (6.9781)  Time: 0.643s,  397.87/s  (0.497s,  514.99/s)  LR: 1.000e-04  Data: 0.204 (0.185)
Train: 0 [  55/5004 (  1%)]  Loss:  6.950780 (6.9776)  Time: 0.289s,  887.16/s  (0.493s,  518.87/s)  LR: 1.000e-04  Data: 0.015 (0.182)
Train: 0 [  56/5004 (  1%)]  Loss:  6.980709 (6.9777)  Time: 0.258s,  992.24/s  (0.489s,  523.25/s)  LR: 1.000e-04  Data: 0.019 (0.179)
Train: 0 [  57/5004 (  1%)]  Loss:  7.007572 (6.9782)  Time: 0.624s,  410.03/s  (0.492s,  520.77/s)  LR: 1.000e-04  Data: 0.019 (0.176)
Train: 0 [  58/5004 (  1%)]  Loss:  6.945206 (6.9776)  Time: 0.484s,  528.42/s  (0.491s,  520.90/s)  LR: 1.000e-04  Data: 0.025 (0.174)
Train: 0 [  59/5004 (  1%)]  Loss:  6.964292 (6.9774)  Time: 0.297s,  861.49/s  (0.488s,  524.36/s)  LR: 1.000e-04  Data: 0.016 (0.171)
Train: 0 [  60/5004 (  1%)]  Loss:  6.981154 (6.9775)  Time: 0.262s,  978.36/s  (0.485s,  528.38/s)  LR: 1.000e-04  Data: 0.022 (0.169)
Train: 0 [  61/5004 (  1%)]  Loss:  6.954180 (6.9771)  Time: 0.239s, 1072.12/s  (0.481s,  532.74/s)  LR: 1.000e-04  Data: 0.019 (0.166)
Train: 0 [  62/5004 (  1%)]  Loss:  6.972757 (6.9770)  Time: 0.536s,  477.19/s  (0.481s,  531.75/s)  LR: 1.000e-04  Data: 0.033 (0.164)
Train: 0 [  63/5004 (  1%)]  Loss:  6.985704 (6.9772)  Time: 0.262s,  975.54/s  (0.478s,  535.56/s)  LR: 1.000e-04  Data: 0.036 (0.162)
Train: 0 [  64/5004 (  1%)]  Loss:  6.976443 (6.9772)  Time: 0.250s, 1025.14/s  (0.474s,  539.52/s)  LR: 1.000e-04  Data: 0.034 (0.160)
Train: 0 [  65/5004 (  1%)]  Loss:  6.980380 (6.9772)  Time: 0.497s,  514.88/s  (0.475s,  539.13/s)  LR: 1.000e-04  Data: 0.034 (0.158)
Train: 0 [  66/5004 (  1%)]  Loss:  6.983441 (6.9773)  Time: 0.788s,  324.90/s  (0.480s,  533.88/s)  LR: 1.000e-04  Data: 0.281 (0.160)
Train: 0 [  67/5004 (  1%)]  Loss:  6.976778 (6.9773)  Time: 0.283s,  904.17/s  (0.477s,  537.11/s)  LR: 1.000e-04  Data: 0.057 (0.158)
Train: 0 [  68/5004 (  1%)]  Loss:  6.997704 (6.9776)  Time: 0.256s,  998.66/s  (0.473s,  540.74/s)  LR: 1.000e-04  Data: 0.032 (0.157)
Train: 0 [  69/5004 (  1%)]  Loss:  6.958188 (6.9773)  Time: 0.264s,  970.40/s  (0.470s,  544.18/s)  LR: 1.000e-04  Data: 0.032 (0.155)
Train: 0 [  70/5004 (  1%)]  Loss:  6.962250 (6.9771)  Time: 0.256s, 1000.05/s  (0.467s,  547.69/s)  LR: 1.000e-04  Data: 0.032 (0.153)
Train: 0 [  71/5004 (  1%)]  Loss:  6.986496 (6.9772)  Time: 0.256s, 1000.63/s  (0.464s,  551.16/s)  LR: 1.000e-04  Data: 0.039 (0.152)
Train: 0 [  72/5004 (  1%)]  Loss:  6.972045 (6.9772)  Time: 0.257s,  997.13/s  (0.462s,  554.56/s)  LR: 1.000e-04  Data: 0.034 (0.150)
Train: 0 [  73/5004 (  1%)]  Loss:  6.985300 (6.9773)  Time: 0.254s, 1009.29/s  (0.459s,  557.95/s)  LR: 1.000e-04  Data: 0.035 (0.148)
Train: 0 [  74/5004 (  1%)]  Loss:  6.932580 (6.9767)  Time: 0.604s,  424.13/s  (0.461s,  555.62/s)  LR: 1.000e-04  Data: 0.321 (0.151)
Train: 0 [  75/5004 (  1%)]  Loss:  6.935655 (6.9761)  Time: 0.249s, 1029.31/s  (0.458s,  559.00/s)  LR: 1.000e-04  Data: 0.019 (0.149)
Train: 0 [  76/5004 (  2%)]  Loss:  6.953679 (6.9758)  Time: 0.242s, 1055.78/s  (0.455s,  562.44/s)  LR: 1.000e-04  Data: 0.025 (0.147)
Train: 0 [  77/5004 (  2%)]  Loss:  6.949023 (6.9755)  Time: 0.264s,  970.38/s  (0.453s,  565.49/s)  LR: 1.000e-04  Data: 0.034 (0.146)
Train: 0 [  78/5004 (  2%)]  Loss:  7.005548 (6.9759)  Time: 0.469s,  545.78/s  (0.453s,  565.23/s)  LR: 1.000e-04  Data: 0.100 (0.145)
Train: 0 [  79/5004 (  2%)]  Loss:  6.955663 (6.9756)  Time: 0.263s,  974.39/s  (0.451s,  568.21/s)  LR: 1.000e-04  Data: 0.016 (0.144)
Train: 0 [  80/5004 (  2%)]  Loss:  6.966527 (6.9755)  Time: 0.260s,  984.75/s  (0.448s,  571.19/s)  LR: 1.000e-04  Data: 0.020 (0.142)
Train: 0 [  81/5004 (  2%)]  Loss:  6.985642 (6.9756)  Time: 0.297s,  861.76/s  (0.446s,  573.55/s)  LR: 1.000e-04  Data: 0.017 (0.141)
Train: 0 [  82/5004 (  2%)]  Loss:  6.982509 (6.9757)  Time: 0.791s,  323.81/s  (0.450s,  568.27/s)  LR: 1.000e-04  Data: 0.456 (0.144)
Train: 0 [  83/5004 (  2%)]  Loss:  6.988305 (6.9759)  Time: 0.310s,  826.51/s  (0.449s,  570.39/s)  LR: 1.000e-04  Data: 0.013 (0.143)
Train: 0 [  84/5004 (  2%)]  Loss:  6.957762 (6.9757)  Time: 0.243s, 1054.03/s  (0.446s,  573.49/s)  LR: 1.000e-04  Data: 0.023 (0.141)
Train: 0 [  85/5004 (  2%)]  Loss:  7.026371 (6.9762)  Time: 0.254s, 1009.11/s  (0.444s,  576.38/s)  LR: 1.000e-04  Data: 0.020 (0.140)
Train: 0 [  86/5004 (  2%)]  Loss:  7.004438 (6.9766)  Time: 0.490s,  522.75/s  (0.445s,  575.70/s)  LR: 1.000e-04  Data: 0.270 (0.142)
Train: 0 [  87/5004 (  2%)]  Loss:  6.926432 (6.9760)  Time: 0.315s,  813.83/s  (0.443s,  577.62/s)  LR: 1.000e-04  Data: 0.052 (0.141)
Train: 0 [  88/5004 (  2%)]  Loss:  6.997172 (6.9762)  Time: 0.270s,  949.69/s  (0.441s,  580.18/s)  LR: 1.000e-04  Data: 0.018 (0.139)
Train: 0 [  89/5004 (  2%)]  Loss:  6.961502 (6.9761)  Time: 0.257s,  994.66/s  (0.439s,  582.88/s)  LR: 1.000e-04  Data: 0.017 (0.138)
Train: 0 [  90/5004 (  2%)]  Loss:  6.958848 (6.9759)  Time: 0.911s,  281.02/s  (0.444s,  576.08/s)  LR: 1.000e-04  Data: 0.680 (0.144)
Train: 0 [  91/5004 (  2%)]  Loss:  6.987521 (6.9760)  Time: 0.265s,  964.34/s  (0.442s,  578.61/s)  LR: 1.000e-04  Data: 0.033 (0.143)
Train: 0 [  92/5004 (  2%)]  Loss:  6.956161 (6.9758)  Time: 0.249s, 1029.27/s  (0.440s,  581.34/s)  LR: 1.000e-04  Data: 0.030 (0.141)
Train: 0 [  93/5004 (  2%)]  Loss:  6.972383 (6.9758)  Time: 0.254s, 1008.03/s  (0.438s,  583.97/s)  LR: 1.000e-04  Data: 0.033 (0.140)
Train: 0 [  94/5004 (  2%)]  Loss:  6.972413 (6.9757)  Time: 0.326s,  786.05/s  (0.437s,  585.56/s)  LR: 1.000e-04  Data: 0.090 (0.140)
Train: 0 [  95/5004 (  2%)]  Loss:  6.974922 (6.9757)  Time: 0.250s, 1024.34/s  (0.435s,  588.18/s)  LR: 1.000e-04  Data: 0.018 (0.138)
Train: 0 [  96/5004 (  2%)]  Loss:  6.991495 (6.9759)  Time: 0.256s, 1001.12/s  (0.433s,  590.70/s)  LR: 1.000e-04  Data: 0.029 (0.137)
Train: 0 [  97/5004 (  2%)]  Loss:  6.982933 (6.9760)  Time: 0.257s,  995.30/s  (0.432s,  593.16/s)  LR: 1.000e-04  Data: 0.031 (0.136)
Train: 0 [  98/5004 (  2%)]  Loss:  6.979902 (6.9760)  Time: 0.847s,  302.42/s  (0.436s,  587.45/s)  LR: 1.000e-04  Data: 0.624 (0.141)
Train: 0 [  99/5004 (  2%)]  Loss:  6.980656 (6.9760)  Time: 0.266s,  962.95/s  (0.434s,  589.75/s)  LR: 1.000e-04  Data: 0.034 (0.140)
